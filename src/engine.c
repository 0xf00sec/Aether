#include <aether.h>
#include <decoder_arm64.h>
#include <decoder_x86.h>

static void write_rel32(uint8_t *p, int32_t v) {memcpy(p, &v, sizeof(v));}
static void write_u64(uint8_t *p, uint64_t v) {memcpy(p, &v, sizeof(v));}

#if defined(__aarch64__) || defined(_M_ARM64)
static bool sketch_flow_arm64(uint8_t *code, size_t size, flowmap *cfg);
static void shuffle_blocks_arm64(uint8_t *code, size_t size, chacha_state_t *rng);
static void flatline_flow_arm64(uint8_t *code, size_t size, flowmap *cfg, chacha_state_t *rng);
#endif


static inline uint8_t get_current_arch(void) {
#if defined(__x86_64__) || defined(_M_X64)
    return ARCH_X86;
#elif defined(__aarch64__) || defined(_M_ARM64)
    return ARCH_ARM;
#else
    return ARCH_X86;
#endif
}

static inline const char* get_arch_name(void) {
#if defined(__x86_64__) || defined(_M_X64)
    return "x86-64";
#elif defined(__aarch64__) || defined(_M_ARM64)
    return "ARM64";
#else
    return "Unknown";
#endif
}

void init_engine(engine_context_t *ctx) {
    if (!ctx) return;
    
    memset(ctx, 0, sizeof(*ctx));
    ctx->debug_code = NULL;
    ctx->debug_code_size = 0;
    ctx->unsafe_mode = false;
    ctx->arch_type = get_current_arch();
    ctx->mutation_count = 0;
    ctx->generation = 0;
    
    DBG("Engine initialized for %s architecture\n", get_arch_name());
}

void drop_mut(muttt_t *log, size_t offset, size_t length,  
                     mutx_type_t type, uint32_t gen, const char *desc) {
    if (!log) return;
    
    if (log->count >= log->cap) {
        size_t new_cap = log->cap ? log->cap * 2 : 4;
        mutx_entry_t *tmp = realloc(log->entries, new_cap * sizeof(mutx_entry_t));
        if (!tmp) {
            return;
        }
        log->entries = tmp;
        log->cap = new_cap;
    }

    mutx_entry_t *entry = &log->entries[log->count++];
    entry->offset = offset;
    entry->length = length;
    entry->type = type;
    entry->gen = gen;
    strncpy(entry->des, desc, 63);
    entry->des[63] = '\0';
}

int init_mut(muttt_t *log) {
    if (!log) return 0;
    
    log->cap = 0;
    log->count = 0;
    log->entries = NULL;
    
    log->entries = malloc(64 * sizeof(mutx_entry_t));
    if (!log->entries) {
        return 0;
    }
    
    log->cap = 64;
    log->count = 0;
    
    memset(log->entries, 0, 64 * sizeof(mutx_entry_t));
    
    return 1;
}

void freeme(muttt_t *log) {
    if (!log) return;
    
    if (log->entries) {
        free(log->entries);
    }
    
    log->entries = NULL;
    log->cap = 0;
    log->count = 0;
}

void boot_live(liveness_state_t *state) {
    if (!state) return;
    
    memset(state, 0, sizeof(*state));
    
#if defined(ARCH_X86)
    state->num_regs = 16;
    state->arch_type = ARCH_X86;
    
    for (int i = 0; i < state->num_regs; i++) {
        state->regs[i].reg = i;
        state->regs[i].iz_live = false;
        state->regs[i].iz_vol = arch_vols[i];
        state->regs[i].def_offset = 0;
        state->regs[i].last_use = 0;
        state->regs[i].is_callee_saved = !arch_vols[i];
    }
    
    state->regs[4].iz_live = true;
    state->regs[5].iz_live = true;
    
#elif defined(ARCH_ARM)
    state->num_regs = 32;
    state->arch_type = ARCH_ARM;
    
    for (int i = 0; i < state->num_regs; i++) {
        state->regs[i].reg = i;
        state->regs[i].iz_live = false;
        state->regs[i].iz_vol = arm64_vols[i];
        state->regs[i].def_offset = 0;
        state->regs[i].last_use = 0;
        state->regs[i].is_callee_saved = !arm64_vols[i];
    }
    
    state->regs[29].iz_live = true;
    state->regs[30].iz_live = true;
    state->regs[31].iz_live = true;
    
#else
    state->num_regs = 16;
    state->arch_type = ARCH_X86;
#endif
}

void pulse_live(liveness_state_t *state, size_t offset, const void *inst_ptr) {
    if (!state || !inst_ptr) return;
    
#if defined(ARCH_X86)
    const x86_inst_t *inst = (const x86_inst_t *)inst_ptr;
    if (!inst || !inst->valid) return;
    
    if (state->num_regs > 4) {
        state->regs[4].iz_live = true;
        state->regs[4].last_use = offset;
    }
    
    if (inst->has_modrm) {
        uint8_t reg = modrm_reg(inst->modrm);
        uint8_t rm = modrm_rm(inst->modrm);
        uint8_t mod = (inst->modrm >> 6) & 3;
        
        if (reg >= 16 || rm >= 16) return;
        
        if (mod != 3) {
            if (inst->has_sib) {
                uint8_t base = inst->sib & 7;
                uint8_t index = (inst->sib >> 3) & 7;
                if (base < 16 && base != 5) {
                    state->regs[base].last_use = offset;
                    state->regs[base].iz_live = true;
                }
                if (index < 16 && index != 4) {
                    state->regs[index].last_use = offset;
                    state->regs[index].iz_live = true;
                }
            } else if (rm < 16) {
                state->regs[rm].last_use = offset;
                state->regs[rm].iz_live = true;
            }
        }
        
        switch (inst->opcode[0]) {
            case 0x89:
                if (mod == 3 && rm < 16) {
                    state->regs[rm].iz_live = true;
                    state->regs[rm].def_offset = offset;
                }
                if (reg < 16) {
                    state->regs[reg].last_use = offset;
                }
                break;
            case 0x8B:
                if (reg < 16) {
                    state->regs[reg].iz_live = true;
                    state->regs[reg].def_offset = offset;
                }
                if (mod == 3 && rm < 16) {
                    state->regs[rm].last_use = offset;
                }
                break;
            case 0x01: case 0x03:
            case 0x29: case 0x2B:
            case 0x31: case 0x33:
            case 0x21: case 0x23:
            case 0x09: case 0x0B:
                if (reg < 16) {
                    state->regs[reg].last_use = offset;
                }
                if (mod == 3 && rm < 16) {
                    state->regs[rm].last_use = offset;
                    state->regs[rm].iz_live = true;
                    state->regs[rm].def_offset = offset;
                }
                break;
            default:
                if (reg < 16) state->regs[reg].last_use = offset;
                if (mod == 3 && rm < 16) state->regs[rm].last_use = offset;
                break;
        }
    }
    
    if ((inst->opcode[0] & 0xF8) == 0xB8) {
        uint8_t reg = inst->opcode[0] & 0x7;
        if (reg < 16) {
            state->regs[reg].iz_live = true;
            state->regs[reg].def_offset = offset;
        }
    }
    
    if ((inst->opcode[0] & 0xF8) == 0x50) {
        uint8_t reg = inst->opcode[0] & 0x7;
        if (reg < 16) {
            state->regs[reg].last_use = offset;
        }
        if (state->num_regs > 4) {
            state->regs[4].last_use = offset;
            state->regs[4].def_offset = offset;
        }
    } else if ((inst->opcode[0] & 0xF8) == 0x58) {
        uint8_t reg = inst->opcode[0] & 0x7;
        if (reg < 16) {
            state->regs[reg].iz_live = true;
            state->regs[reg].def_offset = offset;
        }
        if (state->num_regs > 4) {
            state->regs[4].last_use = offset;
            state->regs[4].def_offset = offset;
        }
    }
    
    if (inst->opcode[0] == 0xE8 || inst->opcode[0] == 0xC3 || 
        inst->opcode[0] == 0xC2 || inst->opcode[0] == 0xCB || inst->opcode[0] == 0xCA) {
        if (state->num_regs > 4) {
            state->regs[4].last_use = offset;
            state->regs[4].def_offset = offset;
        }
    }
    
    if (inst->opcode[0] == 0xF7 || inst->opcode[0] == 0xF6) {
        if (state->num_regs > 0) state->regs[0].last_use = offset;
        if (state->num_regs > 2) state->regs[2].last_use = offset;
    }
    
#elif defined(ARCH_ARM)
    const arm64_inst_t *inst = (const arm64_inst_t *)inst_ptr;
    if (!inst || !inst->valid) return;
    
    if (state->num_regs > 31) {
        state->regs[31].iz_live = true;
        state->regs[31].last_use = offset;
    }
    
    for (uint8_t i = 0; i < inst->num_regs_read; i++) {
        uint8_t reg = inst->regs_read[i];
        if (reg < 32) {
            state->regs[reg].last_use = offset;
            state->regs[reg].iz_live = true;
        }
    }
    
    for (uint8_t i = 0; i < inst->num_regs_written; i++) {
        uint8_t reg = inst->regs_written[i];
        if (reg < 32) {
            state->regs[reg].iz_live = true;
            state->regs[reg].def_offset = offset;
        }
    }
    
    if (inst->is_control_flow) {
        if (inst->type == ARM_OP_BRANCH_LINK) {
            if (state->num_regs > 30) {
                state->regs[30].iz_live = true;
                state->regs[30].def_offset = offset;
            }
        }
        
        if (inst->type == ARM_OP_RET && inst->rn == 30) {
            if (state->num_regs > 30) {
                state->regs[30].last_use = offset;
            }
        }
    }
    
    if (inst->type == ARM_OP_LDR || inst->type == ARM_OP_STR ||
        inst->type == ARM_OP_LDP || inst->type == ARM_OP_STP) {
        if (inst->rn == 31 && state->num_regs > 31) {
            state->regs[31].last_use = offset;
            state->regs[31].iz_live = true;
        }
    }
    
#endif
}

static inline bool is_stackp(uint8_t reg) { 
#if defined(ARCH_X86)
    return reg == 4 || reg == 5; /*  RSP or RBP */
#elif defined(ARCH_ARM)
    return reg == 31 || reg == 29 || reg == 30; /*  SP, FP, LR */
#else
    return reg == 4 || reg == 5;
#endif
}

#if defined(ARCH_ARM)
static inline bool arm64_volatile(uint8_t reg) {
    return reg <= 18;
}

static inline bool callee_saved(uint8_t reg) {
    return reg >= 19 && reg <= 28;
}

static inline bool arm64_special(uint8_t reg) {
    return reg >= 29;
}

static inline bool cool_tmutation(uint8_t reg) {
    return reg < 16 || (reg >= 19 && reg <= 28);
}

static uint8_t jack_reg_arm64(const liveness_state_t *state, uint8_t original_reg,
                              size_t current_offset, chacha_state_t *rng) {
    if (!state || !rng) return original_reg;
    
    if (original_reg >= 29) return original_reg;
    
    if (original_reg >= 32) return original_reg;
    
    uint8_t candidates[19] = {0};
    uint8_t num_candidates = 0;
    
    for (uint8_t reg = 19; reg <= 28; reg++) {
        if (reg == original_reg) continue;
        
        bool is_safe = false;
        if (!state->regs[reg].iz_live) {
            is_safe = true;
        } else if (state->regs[reg].last_use > 0 &&
                   current_offset > state->regs[reg].last_use &&
                   (current_offset - state->regs[reg].last_use) > 32) {
            is_safe = true;
        }
        
        if (is_safe) {
            candidates[num_candidates++] = reg;
        }
    }
    
    if (num_candidates == 0) {
        for (uint8_t reg = 0; reg <= 18; reg++) {
            if (reg == original_reg) continue;
            
            if (reg == 16 || reg == 17) continue;
            
            if (!state->regs[reg].iz_live ||
                (current_offset > state->regs[reg].last_use &&
                 (current_offset - state->regs[reg].last_use) > 16)) {
                candidates[num_candidates++] = reg;
            }
        }
    }
    
    return (num_candidates > 0) ?
           candidates[chacha20_random(rng) % num_candidates] :
           original_reg;
}
#endif

static inline bool has_implicit_rsp_use(uint8_t opcode) {
    return ((opcode & 0xF8) == 0x50) ||
           ((opcode & 0xF8) == 0x58) ||
           (opcode == 0xE8) ||
           (opcode == 0xC3) || (opcode == 0xCB) ||
           (opcode == 0xC2) || (opcode == 0xCA) ||
           (opcode == 0xC8) ||
           (opcode == 0xC9) ||
           (opcode == 0x9C) || (opcode == 0x9D) ||
           (opcode == 0x60) || (opcode == 0x61);
}

#if defined(ARCH_ARM)
static inline uint8_t random_arm_reg(chacha_state_t *rng) {
    if (!rng) return 0;
    
    const uint8_t safe_regs[] = {
        0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
        19, 20, 21, 22, 23, 24, 25, 26, 27, 28
    };
    const size_t num_safe = sizeof(safe_regs) / sizeof(safe_regs[0]);
    
    return safe_regs[chacha20_random(rng) % num_safe];
}
#endif

uint8_t jack_reg(const liveness_state_t *state, uint8_t original_reg, 
                                              size_t current_offset, chacha_state_t *rng) {
    if (!state || !rng) return original_reg;
    
    if (is_stackp(original_reg)) {
        return original_reg;
    }
    
#if defined(ARCH_ARM)
    return jack_reg_arm64(state, original_reg, current_offset, rng);
    
#elif defined(ARCH_X86)
    if (original_reg >= 16) {
        return original_reg;
    }
    
    uint8_t candidates[8] = {0};
    uint8_t num_candidates = 0;
    
    /*  Prefer volatile (caller-saved), non-live registers */
    for (uint8_t reg = 0; reg < 8; reg++) {
        if (reg == original_reg) continue;
        if (reg == 3 || reg == 4 || reg == 5) continue;  /*  Never RBX/RSP/RBP */
        
        bool is_safe = false;
        if (!state->regs[reg].iz_live) {
            is_safe = true;
        } else if (state->regs[reg].last_use > 0 && 
                   current_offset > state->regs[reg].last_use &&
                   (current_offset - state->regs[reg].last_use) > 32) {
            is_safe = true;
        }
        
        if (is_safe && state->regs[reg].iz_vol) {
            candidates[num_candidates++] = reg;
        }
    }
    
    if (num_candidates == 0) {
        for (uint8_t reg = 0; reg < 8; reg++) {
            if (reg == original_reg) continue;
            if (reg == 3 || reg == 4 || reg == 5) continue; 
            
            if (!state->regs[reg].iz_live || 
                (current_offset > state->regs[reg].last_use &&
                 (current_offset - state->regs[reg].last_use) > 64)) { 
                candidates[num_candidates++] = reg;
            }
        }
    }
    
    /*  Validate selected register */
    if (num_candidates > 0) {
        uint8_t selected = candidates[chacha20_random(rng) % num_candidates];
        /*  Paranoid  */
        if (is_stackp(selected)) {
            return original_reg;
        }
        return selected;
    }
    
    return original_reg;
           
#else
    return original_reg;
#endif
}

__attribute__((always_inline)) inline bool is_op_ok(const uint8_t *code) {
#if defined(ARCH_X86)
    x86_inst_t inst;
    if (!decode_x86_withme(code, 16, 0, &inst, NULL)) return false;
    return !inst.ring0 && inst.valid;
#elif defined(ARCH_ARM)
    arm64_inst_t inst;
    if (!decode_arm64(code, &inst)) return false;
    return inst.valid && !inst.ring0;
#else
    return false;
#endif
}

size_t snap_len(const uint8_t *code, size_t maxlen) {
#if defined(ARCH_X86)
    if (maxlen == 0) return 0;
    x86_inst_t inst;
    return decode_x86_withme(code, maxlen, 0, &inst, NULL) ? inst.len : 0;
#elif defined(ARCH_ARM)
    if (maxlen < 4) return 0;
    arm64_inst_t inst;
    return decode_arm64(code, &inst) ? 4 : 0;
#else
    return 0;
#endif
}

/*  Validate a chunk of code */
__attribute__((always_inline)) inline bool is_chunk_ok(const uint8_t *code, size_t max_len) {
    if (!code || max_len == 0) return false;

#if defined(ARCH_ARM) && defined(__aarch64__)
    /*  Must be 4-byte aligned */
    if ((max_len % 4) != 0) return false;
    
    size_t valid_count = 0;
    size_t invalid_count = 0;
    const size_t max_invalid_ratio = max_len / 16;  /*  Stricter for ARM64 */
    
    for (size_t offset = 0; offset + 4 <= max_len; offset += 4) {
        arm64_inst_t inst;
        if (decode_arm64(code + offset, &inst) && inst.valid && !inst.ring0) {
            valid_count++;
            invalid_count = 0;
        } else {
            invalid_count++;
            if (invalid_count > max_invalid_ratio) return false;
        }
    }
    
    return valid_count > 0 && (invalid_count * 10 < valid_count);
    
#else
    size_t offset = 0;
    size_t valid_count = 0;
    size_t invalid_count = 0;

    const size_t max_invalid_ratio = max_len / 8;
    const size_t max_single_invalid = max_len / 20; 

    while (offset < max_len) {
        size_t len = snap_len(code + offset, max_len - offset);

        if (!len) {
            invalid_count++;
            if (invalid_count > max_invalid_ratio) return false;
            offset++;
            continue;
        }

        if (offset + len > max_len) return false;

        if (is_op_ok(code + offset)) {
            valid_count++;
            invalid_count = 0; 
        } else {
            invalid_count++;
            if (invalid_count > max_single_invalid) return false;
        }

        offset += len;
    }
    /*  allow max 2% invalid instructions */
    return valid_count > 0 && (invalid_count * 50 < valid_count);
#endif
}

__attribute__((always_inline)) inline void forge_ghost_x86(uint8_t *buf, size_t *len, uint32_t value, chacha_state_t *rng) {
    if (!buf || !len || !rng) return;
    
    /*  Use only volatile/scratch reg, avoid RSP(4) and RBP(5) */
    const uint8_t safe_regs[] = {0, 1, 2, 6, 7}; /*  RAX, RCX, RDX, RSI, RDI */
    const size_t num_safe = sizeof(safe_regs) / sizeof(safe_regs[0]);
    
    uint8_t reg1 = safe_regs[chacha20_random(rng) % num_safe];
    uint8_t reg2 = safe_regs[chacha20_random(rng) % num_safe];
    uint8_t reg3 = safe_regs[chacha20_random(rng) % num_safe];
    while (reg2 == reg1) reg2 = safe_regs[chacha20_random(rng) % num_safe];
    while (reg3 == reg1 || reg3 == reg2) reg3 = safe_regs[chacha20_random(rng) % num_safe];

    uint8_t imm8 = chacha20_random(rng) & 0xFF;
    uint64_t imm64 = ((uint64_t)chacha20_random(rng) << 32) | chacha20_random(rng);

    switch (chacha20_random(rng) % 12) {
        case 0: { /* XOR + TEST + JZ - always zero, always jumps */
            buf[0] = 0x48; buf[1] = 0x31; buf[2] = 0xC0 | (reg1 << 3) | reg1; /*  xor reg1, reg1 */
            buf[3] = 0x48; buf[4] = 0x85; buf[5] = 0xC0 | (reg1 << 3) | reg1; /*  test reg1, reg1 */
            buf[6] = 0x0F; buf[7] = 0x84;                                      /*  jz (always taken) */
            write_rel32(buf + 8, 0); /*  Jump to next instruction (dead code) */
            /*  Dead code that will never execute */
            buf[12] = 0x48; buf[13] = 0x83; buf[14] = 0xC0 | reg1; buf[15] = imm8;
            buf[16] = 0x48; buf[17] = 0x83; buf[18] = 0xE8 | reg1; buf[19] = imm8;
            *len = 20;
            break;
        }
        case 1: { /* MOV + XOR + TEST + JNZ */
            buf[0] = 0x48; buf[1] = 0x89; buf[2] = 0xC0 | (reg2 << 3) | reg1;
            buf[3] = 0x48; buf[4] = 0x31; buf[5] = 0xC0 | (reg2 << 3) | reg2;
            buf[6] = 0x48; buf[7] = 0x85; buf[8] = 0xC0 | (reg2 << 3) | reg2;
            buf[9] = 0x0F; buf[10] = 0x85;
            write_rel32(buf + 11, 12);
            buf[15] = 0x68; write_rel32(buf + 16, (uint32_t)imm64);
            buf[20] = 0x48; buf[21] = 0x81; buf[22] = 0xC0 | reg2; write_rel32(buf + 23, (uint32_t)imm64);
            buf[27] = (uint8_t)(0x58 + reg2);
            *len = 28;
            break;
        }
        case 2: { /* LEA + CMP + JE */
            buf[0] = 0x48; buf[1] = 0x8D; buf[2] = 0x05 | (reg1 << 3); write_rel32(buf + 3, 12);
            buf[7] = 0x48; buf[8] = 0x39; buf[9] = 0xC0 | (reg1 << 3) | reg1;
            buf[10] = 0x0F; buf[11] = 0x84;
            write_rel32(buf + 12, 8);
            buf[16] = 0x48; buf[17] = 0x83; buf[18] = 0xC0 | reg1; buf[19] = imm8;
            buf[20] = 0x48; buf[21] = 0x83; buf[22] = 0xE8 | reg1; buf[23] = imm8;
            *len = 24;
            break;
        }
        case 3: { /* SUB + TEST + JZ */
            buf[0] = 0x48; buf[1] = 0x29; buf[2] = 0xC0 | (reg1 << 3) | reg1;
            buf[3] = 0x48; buf[4] = 0x85; buf[5] = 0xC0 | (reg1 << 3) | reg1;
            buf[6] = 0x0F; buf[7] = 0x84;
            write_rel32(buf + 8, 12);
            buf[12] = 0x48; buf[13] = 0x81; buf[14] = 0xC0 | reg1; write_rel32(buf + 15, (uint32_t)imm64);
            buf[19] = 0x48; buf[20] = 0x81; buf[21] = 0xE8 | reg1; write_rel32(buf + 22, (uint32_t)imm64);
            *len = 26;
            break;
        }
        case 4: { /* AND + TEST + JZ */
            buf[0] = 0x48; buf[1] = 0x83; buf[2] = 0xE0 | reg1; buf[3] = imm8;
            buf[4] = 0x48; buf[5] = 0x85; buf[6] = 0xC0 | (reg1 << 3) | reg1;
            buf[7] = 0x0F; buf[8] = 0x84;
            write_rel32(buf + 9, 14);
            buf[13] = 0x48; buf[14] = 0x87; buf[15] = 0xC0 | (reg1 << 3) | reg3;
            buf[16] = 0x48; buf[17] = 0x87; buf[18] = 0xC0 | (reg3 << 3) | reg1;
            buf[19] = 0x48; buf[20] = 0x83; buf[21] = 0xC0 | reg1; buf[22] = imm8;
            *len = 23;
            break;
        }
        case 5: { /* PUSH + POP + TEST + JZ */
            buf[0] = (uint8_t)(0x50 | reg1);
            buf[1] = (uint8_t)(0x58 | reg1);
            buf[2] = 0x48; buf[3] = 0x85; buf[4] = 0xC0 | (reg1 << 3) | reg1;
            buf[5] = 0x0F; buf[6] = 0x84;
            write_rel32(buf + 7, 10);
            buf[11] = 0x48; buf[12] = 0x83; buf[13] = 0xC0 | reg1; buf[14] = imm8;
            buf[15] = 0x48; buf[16] = 0x83; buf[17] = 0xE8 | reg1; buf[18] = imm8;
            *len = 19;
            break;
        }
        case 6: { /* XCHG + TEST + JZ */
            buf[0] = 0x48; buf[1] = 0x87; buf[2] = 0xC0 | (reg1 << 3) | reg2;
            buf[3] = 0x48; buf[4] = 0x85; buf[5] = 0xC0 | (reg1 << 3) | reg1;
            buf[6] = 0x0F; buf[7] = 0x84;
            write_rel32(buf + 8, 11);
            buf[12] = 0x48; buf[13] = 0x87; buf[14] = 0xC0 | (reg1 << 3) | reg2;
            buf[15] = 0x48; buf[16] = 0x83; buf[17] = 0xC0 | reg1; buf[18] = imm8;
            buf[19] = 0x48; buf[20] = 0x83; buf[21] = 0xE8 | reg1; buf[22] = imm8;
            *len = 23;
            break;
        }
        case 7: { /* ADD + SUB + TEST + JZ */
            buf[0] = 0x48; buf[1] = 0x83; buf[2] = 0xC0 | reg1; buf[3] = imm8;
            buf[4] = 0x48; buf[5] = 0x83; buf[6] = 0xE8 | reg1; buf[7] = imm8;
            buf[8] = 0x48; buf[9] = 0x85; buf[10] = 0xC0 | (reg1 << 3) | reg1;
            buf[11] = 0x0F; buf[12] = 0x84;
            write_rel32(buf + 13, 14);
            buf[17] = 0x68; write_rel32(buf + 18, (uint32_t)imm64);
            buf[22] = 0x48; buf[23] = 0x81; buf[24] = 0xC0 | reg2; write_rel32(buf + 25, (uint32_t)imm64);
            buf[29] = (uint8_t)(0x58 + reg2);
            *len = 30;
            break;
        }
        case 8: { /* MOV + ADD + CMP + JNE */
            buf[0] = 0x48; buf[1] = 0xB8 | reg1;
            write_rel32(buf + 2, imm64);
            buf[10] = 0x48; buf[11] = 0x83; buf[12] = 0xC0 | reg1; buf[13] = imm8;
            buf[14] = 0x48; buf[15] = 0x3B; buf[16] = 0xC0 | (reg1 << 3) | reg1;
            buf[17] = 0x0F; buf[18] = 0x85;
            write_rel32(buf + 19, 6);
            buf[23] = 0x48; buf[24] = 0x83; buf[25] = 0xE8 | reg1; buf[26] = imm8;
            buf[27] = 0x48; buf[28] = 0x83; buf[29] = 0xC0 | reg1; buf[30] = imm8;
            *len = 31;
            break;
        }
        case 9: { /* OR + TEST + JNZ */
            buf[0] = 0x48; buf[1] = 0x83; buf[2] = 0xC8 | reg1; buf[3] = imm8;
            buf[4] = 0x48; buf[5] = 0x85; buf[6] = 0xC0 | (reg1 << 3) | reg1;
            buf[7] = 0x0F; buf[8] = 0x85;
            write_rel32(buf + 9, 10);
            buf[13] = 0x48; buf[14] = 0x83; buf[15] = 0xE0 | reg1; buf[16] = ~imm8;
            buf[17] = 0x48; buf[18] = 0x83; buf[19] = 0xC8 | reg1; buf[20] = imm8;
            *len = 21;
            break;
        }
        case 10: { /* NEG + TEST + JZ */
            buf[0] = 0x48; buf[1] = 0xF7; buf[2] = 0xD8 | reg1;
            buf[3] = 0x48; buf[4] = 0x85; buf[5] = 0xC0 | (reg1 << 3) | reg1;
            buf[6] = 0x0F; buf[7] = 0x84;
            write_rel32(buf + 8, 10);
            buf[12] = 0x48; buf[13] = 0xF7; buf[14] = 0xD8 | reg1;
            buf[15] = 0x48; buf[16] = 0x83; buf[17] = 0xC0 | reg1; buf[18] = imm8;
            buf[19] = 0x48; buf[20] = 0x83; buf[21] = 0xE8 | reg1; buf[22] = imm8;
            *len = 23;
            break;
        }
        default: { /* Complex multi-register sequence */
            buf[0] = 0x48; buf[1] = 0x89; buf[2] = 0xC0 | (reg2 << 3) | reg1;
            buf[3] = 0x48; buf[4] = 0x89; buf[5] = 0xC0 | (reg3 << 3) | reg2;
            buf[6] = 0x48; buf[7] = 0x31; buf[8] = 0xC0 | (reg1 << 3) | reg1;
            buf[9] = 0x48; buf[10] = 0x85; buf[11] = 0xC0 | (reg1 << 3) | reg1;
            buf[12] = 0x0F; buf[13] = 0x84;
            write_rel32(buf + 14, 16);
            buf[18] = 0x48; buf[19] = 0x83; buf[20] = 0xC0 | reg1; buf[21] = imm8;
            buf[22] = 0x48; buf[23] = 0x83; buf[24] = 0xE8 | reg1; buf[25] = imm8;
            buf[26] = 0x48; buf[27] = 0x89; buf[28] = 0xC0 | (reg1 << 3) | reg2;
            buf[29] = 0x48; buf[30] = 0x89; buf[31] = 0xC0 | (reg2 << 3) | reg3;
            *len = 32;
            break;
        }
    }
}

/* Generate ARM64 opaque predicates always-taken/never-taken branches with dead code */
__attribute__((always_inline)) inline void forge_ghost_arm(uint8_t *buf, size_t *len, uint32_t value, chacha_state_t *rng) {
    if (!buf || !len || !rng) return;
    
    uint8_t reg1 = random_arm_reg(rng);
    uint8_t reg2 = random_arm_reg(rng);
    uint8_t reg3 = random_arm_reg(rng);
    
    while (reg2 == reg1) reg2 = random_arm_reg(rng);
    while (reg3 == reg1 || reg3 == reg2) reg3 = random_arm_reg(rng);
    
    int32_t skip_offset = 2;
    uint32_t branch_imm = (skip_offset & 0x7FFFF) << 5;
    
    switch(chacha20_random(rng) % 10) {
        case 0: {
            *(uint32_t*)buf = 0xD2800000 | (1u << 31) | reg1;
            *(uint32_t*)(buf + 4) = 0xB4000000 | (1u << 31) | reg1 | branch_imm;
            *(uint32_t*)(buf + 8) = 0xD2800000 | (1u << 31) | reg2 | (0xFF << 5);
            *(uint32_t*)(buf + 12) = 0x91000000 | (1u << 31) | reg2 | (reg2 << 5) | (1 << 10);
            *len = 16;
            break;
        }
        case 1: {
            *(uint32_t*)buf = 0xEB000000 | (1u << 31) | 31 | (reg1 << 5) | (reg1 << 16);
            *(uint32_t*)(buf + 4) = 0x54000000 | branch_imm;
            *(uint32_t*)(buf + 8) = 0xD503201F;
            *(uint32_t*)(buf + 12) = 0xD503201F;
            *len = 16;
            break;
        }
        case 2: {
            *(uint32_t*)buf = 0xCA000000 | (1u << 31) | reg1 | (reg2 << 5) | (reg2 << 16);
            *(uint32_t*)(buf + 4) = 0x54000000 | branch_imm;
            *(uint32_t*)(buf + 8) = 0x91000000 | (1u << 31) | reg1 | (reg1 << 5) | (0xFF << 10);
            *len = 12;
            break;
        }
        case 3: {
            *(uint32_t*)buf = 0x72000000 | (1u << 31) | 31 | (reg1 << 5);
            *(uint32_t*)(buf + 4) = 0x54000001 | branch_imm;
            *(uint32_t*)(buf + 8) = 0xD503201F;
            *len = 12;
            break;
        }
        case 4: {
            *(uint32_t*)buf = 0xCB000000 | (1u << 31) | reg1 | (reg2 << 5) | (reg2 << 16);
            *(uint32_t*)(buf + 4) = 0xB4000000 | (1u << 31) | reg1 | branch_imm;
            *(uint32_t*)(buf + 8) = 0xD2800000 | (1u << 31) | reg3 | (0xAA << 5);
            *len = 12;
            break;
        }
        case 5: {
            *(uint32_t*)buf = 0xCA000000 | (1u << 31) | reg1 | (reg2 << 5) | (reg2 << 16);
            *(uint32_t*)(buf + 4) = 0xB5000000 | (1u << 31) | reg1 | branch_imm;
            *(uint32_t*)(buf + 8) = 0xD503201F;
            *len = 12;
            break;
        }
        case 6: {
            *(uint32_t*)buf = 0x72000000 | (1u << 31) | 31 | (reg1 << 5);
            *(uint32_t*)(buf + 4) = 0x54000001 | branch_imm;
            *(uint32_t*)(buf + 8) = 0xD503201F;
            *len = 12;
            break;
        }
        case 7: {
            *(uint32_t*)buf = 0xEB000000 | (1u << 31) | 31 | (reg1 << 5) | (reg1 << 16);
            *(uint32_t*)(buf + 4) = 0x54000000 | branch_imm;
            *(uint32_t*)(buf + 8) = 0x91000000 | (1u << 31) | reg2 | (reg2 << 5) | (1 << 10);
            *len = 12;
            break;
        }
        case 8: {
            *(uint32_t*)buf = 0x92400000 | (1u << 31) | reg1 | (reg2 << 5);
            *(uint32_t*)(buf + 4) = 0xB4000000 | (1u << 31) | reg1 | branch_imm;
            *(uint32_t*)(buf + 8) = 0xD2800000 | (1u << 31) | reg3 | (0x55 << 5);
            *len = 12;
            break;
        }
        case 9: {
            *(uint32_t*)buf = 0xAA1F03E0 | (1u << 31) | reg1 | (31 << 5);
            *(uint32_t*)(buf + 4) = 0xB5000000 | (1u << 31) | reg1 | branch_imm;
            *(uint32_t*)(buf + 8) = 0xD503201F;
            *len = 12;
            break;
        }
    }
}

/* Unified opaque predicate generator */
#if defined(ARCH_X86)
    #define forge_ghost forge_ghost_x86
#elif defined(ARCH_ARM)
    #define forge_ghost forge_ghost_arm
#endif

#if defined(ARCH_ARM)
/* Generate ARM64 junk instructions semantically useless but valid code */
static void spew_trash_arm64(uint8_t *buf, size_t *len, chacha_state_t *rng) {
    if (!buf || !len || !rng) return;
    
    uint8_t r1 = random_arm_reg(rng);
    uint8_t r2 = random_arm_reg(rng);
    while (r2 == r1) r2 = random_arm_reg(rng);
    
    uint8_t choice = chacha20_random(rng) % 15;
    uint32_t insn = 0;
    
    switch (choice) {
        case 0:
            insn = 0xD503201F;
            break;
        case 1:
            insn = 0xAA0003E0 | (1u << 31) | r1 | (r1 << 16) | (31 << 5);
            break;
        case 2:
            insn = 0x91000000 | (1u << 31) | r1 | (r1 << 5);
            break;
        case 3:
            insn = 0xD1000000 | (1u << 31) | r1 | (r1 << 5);
            break;
        case 4:
            insn = 0xAA1F0000 | (1u << 31) | r1 | (r1 << 5);
            break;
        case 5:
            insn = 0xCA1F0000 | (1u << 31) | r1 | (r1 << 5);
            break;
        case 6:
            insn = 0x8A000000 | (1u << 31) | r1 | (r1 << 5) | (r1 << 16);
            break;
        case 7:
            insn = 0xAA000000 | (1u << 31) | r1 | (r1 << 5) | (r1 << 16);
            break;
        case 8:
            insn = 0xAA0003E0 | (1u << 31) | r1 | (r2 << 16) | (31 << 5);
            break;
        case 9:
            insn = 0xD3400000 | (1u << 31) | r1 | (r1 << 5);
            break;
        case 10:
            insn = 0xD340FC00 | (1u << 31) | r1 | (r1 << 5);
            break;
        case 11:
            insn = 0xD2800000 | (1u << 31) | r1;
            break;
        case 12:
            insn = 0xCA1F03E0 | (1u << 31) | r1 | (31 << 5);
            break;
        case 13:
            insn = 0xAA1F03E0 | (1u << 31) | r1 | (31 << 5);
            break;
        case 14:
            insn = 0x8B1F03E0 | (1u << 31) | r1 | (31 << 5);
            break;
    }
    
    *(uint32_t*)buf = insn;
    *len = 4;
}
#endif

void spew_trash(uint8_t *buf, size_t *len, chacha_state_t *rng) {
    if (!buf || !len || !rng) return;

#if defined(ARCH_ARM)
    spew_trash_arm64(buf, len, rng);
#elif defined(ARCH_X86)
    /* Only use volatile regs to avoid save/restore overhead */
    const uint8_t usable_regs[] = {0,1,2,6,7,8,9,10,11};
    size_t reg_count = sizeof(usable_regs) / sizeof(usable_regs[0]);

    uint8_t r1 = usable_regs[chacha20_random(rng) % reg_count];
    uint8_t r2;
    do { r2 = usable_regs[chacha20_random(rng) % reg_count]; } while (r2 == r1);

    uint8_t choice = chacha20_random(rng) % 20;

    switch(choice) {
        case 0: buf[0] = 0x90; *len = 1; break;
        case 1: buf[0]=0x66; buf[1]=0x90; *len=2; break;
        case 2: buf[0]=0x48; buf[1]=0x89; buf[2]=0xC0 | (r1<<3) | r2; *len=3; break;
        case 3: buf[0]=0x48; buf[1]=0x31; buf[2]=0xC0 | (r1<<3) | r1; *len=3; break;
        case 4: buf[0]=0x48; buf[1]=0x8D; buf[2]=0x40 | r1; buf[3]=0x00; *len=4; break;
        case 5: buf[0]=0x48; buf[1]=0x83; buf[2]=0xC0 | r1; buf[3]=0x00; *len=4; break;
        case 6: buf[0]=0x48; buf[1]=0x83; buf[2]=0xE8; buf[3]=r1; *len=4; break;
        case 7: 
            if (r1 < 8) { buf[0]=0x50|r1; buf[1]=0x58|r1; *len=2; } 
            else { buf[0]=0x90; *len=1; } 
            break;
        case 8: buf[0]=0x48; buf[1]=0x85; buf[2]=0xC0 | (r1<<3) | r1; *len=3; break;
        case 9: buf[0]=0x48; buf[1]=0x39; buf[2]=0xC0 | (r1<<3) | r1; *len=3; break;
        case 10: buf[0]=0x48; buf[1]=0x09; buf[2]=0xC0 | (r1<<3) | r1; *len=3; break;
        case 11: buf[0]=0x48; buf[1]=0x21; buf[2]=0xC0 | (r1<<3) | r1; *len=3; break;
        case 12: buf[0]=0x48; buf[1]=0x87; buf[2]=0xC0 | (r1<<3) | r1; *len=3; break;
        case 13: buf[0]=0x0F; buf[1]=0x1F; buf[2]=0x00; *len=3; break;
        case 14: buf[0]=0x0F; buf[1]=0x1F; buf[2]=0x40; buf[3]=0x00; *len=4; break;
        case 15: buf[0]=0x48; buf[1]=0x89; buf[2]=0xC0 | (r1<<3) | r2; *len=3; break;
        case 16: buf[0]=0x48; buf[1]=0x31; buf[2]=0xC0 | (r1<<3) | r2; *len=3; break;
        case 17: buf[0]=0x48; buf[1]=0x01; buf[2]=0xC0 | (r2<<3) | r1; *len=3; break;
        case 18: buf[0]=0x48; buf[1]=0x29; buf[2]=0xC0 | (r2<<3) | r1; *len=3; break;
        case 19: buf[0]=0x0F; buf[1]=0x1F; buf[2]=0x40 | (chacha20_random(rng) % 8); buf[3]=0x00; *len=4; break;
    }
#else
    buf[0] = 0x90;
    *len = 1;
#endif
}

static inline bool cfg_terminator(const x86_inst_t *inst) { 
    if (!inst || !inst->valid) return false;
    uint8_t op = inst->opcode[0];
    
    if (op == 0xE9 || op == 0xEB) return true;
    if (op == 0xC3 || op == 0xC2 || op == 0xCB || op == 0xCA) return true;
    
    if (op == 0xFF && inst->has_modrm) {
        uint8_t reg = modrm_reg(inst->modrm);
        if (reg == 4 || reg == 5) return true;
    }
    
    return false;
}

static inline bool branch_if(const x86_inst_t *inst) { 
    if (!inst || !inst->valid) return false;
    uint8_t op = inst->opcode[0];
    
    if (op >= 0x70 && op <= 0x7F) return true;
    if (op == 0xE0 || op == 0xE1 || op == 0xE2 || op == 0xE3) return true;
    if (op == 0x0F && inst->opcode_len > 1 && 
        inst->opcode[1] >= 0x80 && inst->opcode[1] <= 0x8F) return true;
    
    return false;
}

#if defined(__aarch64__) || defined(_M_ARM64)
/* Build control flow graph for ARM64 identifies basic blocks and successors */
static bool sketch_flow_arm64(uint8_t *code, size_t size, flowmap *cfg) {
    if (!code || !cfg || size < 4 || (size % 4) != 0) {
        if (cfg) *cfg = (flowmap){0};
        return false;
    }

    /* Phase 1: Mark block leaders (entry point + branch targets) */
    bool *leaders = calloc(size, sizeof(bool));
    if (!leaders) return false;
    
    leaders[0] = true;
    
    for (size_t offset = 0; offset + 4 <= size; offset += 4) {
        arm64_inst_t inst;
        
        if (offset + 4 > size) break;
        
        if (!decode_arm64(code + offset, &inst) || !inst.valid) {
            continue;
        }
        
        if (inst.is_control_flow) {
            if (inst.type == ARM_OP_BRANCH_COND || inst.type == ARM_OP_CBZ || 
                inst.type == ARM_OP_CBNZ || inst.type == ARM_OP_TBZ || 
                inst.type == ARM_OP_TBNZ || inst.type == ARM_OP_BRANCH_LINK) {
                size_t next_offset = offset + 4;
                if (next_offset < size) {
                    leaders[next_offset] = true;
                }
            }
            
            if (inst.type == ARM_OP_BRANCH || inst.type == ARM_OP_BRANCH_LINK ||
                inst.type == ARM_OP_BRANCH_COND || inst.type == ARM_OP_CBZ ||
                inst.type == ARM_OP_CBNZ || inst.type == ARM_OP_TBZ || 
                inst.type == ARM_OP_TBNZ) {
                
                int64_t target = (int64_t)offset + inst.target;
                
                if (target >= 0 && (size_t)target < size && ((size_t)target % 4) == 0) {
                    leaders[(size_t)target] = true;
                }
            }
        }
    }
    
    /* Phase 2: Create blocks from leaders */
    const size_t initial_cap = 1024;
    cfg->blocks = calloc(initial_cap, sizeof(blocknode));
    if (!cfg->blocks) {
        free(leaders);
        return false;
    }
    
    cfg->num_blocks = 0;
    cfg->cap_blocks = initial_cap;
    
    size_t block_start = 0;
    for (size_t i = 4; i < size; i += 4) {
        if (leaders[i]) {
            if (cfg->num_blocks < cfg->cap_blocks) {
                cfg->blocks[cfg->num_blocks].start = block_start;
                cfg->blocks[cfg->num_blocks].end = i;
                cfg->blocks[cfg->num_blocks].id = cfg->num_blocks;
                cfg->blocks[cfg->num_blocks].num_successors = 0;
                cfg->blocks[cfg->num_blocks].is_exit = false;
                cfg->num_blocks++;
            }
            block_start = i;
        }
    }
    
    if (block_start < size && cfg->num_blocks < cfg->cap_blocks) {
        cfg->blocks[cfg->num_blocks].start = block_start;
        cfg->blocks[cfg->num_blocks].end = size;
        cfg->blocks[cfg->num_blocks].id = cfg->num_blocks;
        cfg->blocks[cfg->num_blocks].num_successors = 0;
        cfg->blocks[cfg->num_blocks].is_exit = false;
        cfg->num_blocks++;
    }
    
    /* Phase 3: Build successor relationships */
    for (size_t bi = 0; bi < cfg->num_blocks; bi++) {
        blocknode *block = &cfg->blocks[bi];
        
        /*  Find last instruction in block */
        if (block->end <= block->start || block->end > size) continue;
        
        size_t last_insn_offset = block->end - 4;
        if (last_insn_offset < block->start) continue;
        
        arm64_inst_t inst;
        if (!decode_arm64(code + last_insn_offset, &inst) || !inst.valid) {
            /*  If we can't decode last instruction, assume fall-through */
            if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                block->successors[block->num_successors++] = bi + 1;
            }
            continue;
        }
        
        if (inst.type == ARM_OP_RET) {
            block->is_exit = true;
        }
        else if (inst.type == ARM_OP_BRANCH) {
            int64_t target = (int64_t)last_insn_offset + inst.target;
            if (target >= 0 && (size_t)target < size) {
                for (size_t ti = 0; ti < cfg->num_blocks; ti++) {
                    if ((size_t)target >= cfg->blocks[ti].start && 
                        (size_t)target < cfg->blocks[ti].end) {
                        if (block->num_successors < 4) {
                            block->successors[block->num_successors++] = ti;
                        }
                        break;
                    }
                }
            }
        }
        else if (inst.type == ARM_OP_BRANCH_COND || inst.type == ARM_OP_CBZ ||
                 inst.type == ARM_OP_CBNZ || inst.type == ARM_OP_TBZ || 
                 inst.type == ARM_OP_TBNZ) {
            int64_t target = (int64_t)last_insn_offset + inst.target;
            
            if (target >= 0 && (size_t)target < size) {
                for (size_t ti = 0; ti < cfg->num_blocks; ti++) {
                    if ((size_t)target >= cfg->blocks[ti].start && 
                        (size_t)target < cfg->blocks[ti].end) {
                        if (block->num_successors < 4) {
                            block->successors[block->num_successors++] = ti;
                        }
                        break;
                    }
                }
            }
            
            if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                block->successors[block->num_successors++] = bi + 1;
            }
        }
        else if (inst.type == ARM_OP_BRANCH_LINK) {
            if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                block->successors[block->num_successors++] = bi + 1;
            }
        }
        else if (inst.type == ARM_OP_BR || inst.type == ARM_OP_BLR) {
            /* Indirect branches can't determine target statically */
            if (inst.type == ARM_OP_BR) {
                block->is_exit = true;
            } else {
                if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                    block->successors[block->num_successors++] = bi + 1;
                }
            }
        }
        else {
            if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                block->successors[block->num_successors++] = bi + 1;
            }
        }
    }
    
    cfg->entry_block = 0;
    cfg->exit_block = cfg->num_blocks > 0 ? cfg->num_blocks - 1 : 0;
    
    free(leaders);
    
    DBG("Built CFG with %zu blocks\n", cfg->num_blocks);
    return cfg->num_blocks > 0;
}
#endif  // __aarch64__ || _M_ARM64

bool sketch_flow(uint8_t *code, size_t size, flowmap *cfg) {
#if defined(__aarch64__) || defined(_M_ARM64)
    return sketch_flow_arm64(code, size, cfg);
#elif defined(__x86_64__) || defined(_M_X64)
    if (!code || !cfg || size < 16) {
        if (cfg) *cfg = (flowmap){0};
        return false;
    }

    bool *leaders = calloc(size, sizeof(bool));
    if (!leaders) return false;
    
    leaders[0] = true;
    
    size_t offset = 0;
    while (offset < size) {
        x86_inst_t inst;
        if (!decode_x86_withme(code + offset, size - offset, 0, &inst, NULL) || 
            !inst.valid || inst.len == 0) {
            offset++;
            continue;
        }
        
        if (cfg_terminator(&inst) || branch_if(&inst)) {
            if (offset + inst.len < size) {
                leaders[offset + inst.len] = true;
            }
            
            int64_t target = -1;
            if (inst.opcode[0] == 0xE9 || inst.opcode[0] == 0xE8) {  /*  JMP/CALL rel32 */
                target = offset + inst.len + (int32_t)inst.imm;
            } else if (inst.opcode[0] == 0xEB) {  /*  JMP rel8 */
                target = offset + inst.len + (int8_t)inst.imm;
            } else if (inst.opcode[0] >= 0x70 && inst.opcode[0] <= 0x7F) {  /*  Jcc rel8 */
                target = offset + inst.len + (int8_t)inst.imm;
            } else if (inst.opcode[0] == 0x0F && inst.opcode_len > 1 &&
                       inst.opcode[1] >= 0x80 && inst.opcode[1] <= 0x8F) {  /*  Jcc rel32 */
                target = offset + inst.len + (int32_t)inst.imm;
            }
            
            /*  Mark jump target as a leader */
            if (target >= 0 && target < (int64_t)size) {
                leaders[target] = true;
            }
        }
        
        offset += inst.len;
    }
    
    const size_t initial_cap = 1024;
    cfg->blocks = calloc(initial_cap, sizeof(blocknode));
    if (!cfg->blocks) {
        free(leaders);
        return false;
    }
    
    cfg->num_blocks = 0;
    cfg->cap_blocks = initial_cap;
    
    size_t block_start = 0;
    for (size_t i = 0; i < size; i++) {
        if (leaders[i] && i > block_start) {
            if (cfg->num_blocks < cfg->cap_blocks) {
                cfg->blocks[cfg->num_blocks].start = block_start;
                cfg->blocks[cfg->num_blocks].end = i;
                cfg->blocks[cfg->num_blocks].id = cfg->num_blocks;
                cfg->blocks[cfg->num_blocks].num_successors = 0;
                cfg->blocks[cfg->num_blocks].is_exit = false;
                cfg->num_blocks++;
            }
            block_start = i;
        }
    }
    
    if (block_start < size && cfg->num_blocks < cfg->cap_blocks) {
        cfg->blocks[cfg->num_blocks].start = block_start;
        cfg->blocks[cfg->num_blocks].end = size;
        cfg->blocks[cfg->num_blocks].id = cfg->num_blocks;
        cfg->blocks[cfg->num_blocks].num_successors = 0;
        cfg->blocks[cfg->num_blocks].is_exit = false;
        cfg->num_blocks++;
    }
    
    for (size_t bi = 0; bi < cfg->num_blocks; bi++) {
        blocknode *block = &cfg->blocks[bi];
        
        if (block->end <= block->start || block->end > size) continue;
        
        size_t last_insn_offset = block->end;
        x86_inst_t last_inst = {0};
        bool found_last = false;
        
        size_t scan_offset = block->start;
        while (scan_offset < block->end) {
            x86_inst_t inst;
            if (decode_x86_withme(code + scan_offset, block->end - scan_offset, 0, &inst, NULL) &&
                inst.valid && inst.len > 0) {
                last_insn_offset = scan_offset;
                last_inst = inst;
                found_last = true;
                scan_offset += inst.len;
            } else {
                scan_offset++;
            }
        }
        
        if (!found_last) {
            if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                block->successors[block->num_successors++] = bi + 1;
            }
            continue;
        }
        
        uint8_t op = last_inst.opcode[0];
        
        if (op == 0xC3 || op == 0xCB || op == 0xC2 || op == 0xCA) {
            block->is_exit = true;
        }
        else if (op == 0xE9 || op == 0xEB) {
            int64_t target = last_insn_offset + last_inst.len;
            if (op == 0xE9) {
                target += (int32_t)last_inst.imm;
            } else {
                target += (int8_t)last_inst.imm;
            }
            
            if (target >= 0 && (size_t)target < size) {
                for (size_t ti = 0; ti < cfg->num_blocks; ti++) {
                    if ((size_t)target >= cfg->blocks[ti].start && 
                        (size_t)target < cfg->blocks[ti].end) {
                        if (block->num_successors < 4) {
                            block->successors[block->num_successors++] = ti;
                        }
                        break;
                    }
                }
            }
        }
        else if ((op >= 0x70 && op <= 0x7F) || 
                 (op == 0x0F && last_inst.opcode_len > 1 && 
                  last_inst.opcode[1] >= 0x80 && last_inst.opcode[1] <= 0x8F)) {
            int64_t target = last_insn_offset + last_inst.len;
            
            if (op >= 0x70 && op <= 0x7F) {
                target += (int8_t)last_inst.imm;
            } else {
                target += (int32_t)last_inst.imm;
            }
            
            /*  Add branch target */
            if (target >= 0 && (size_t)target < size) {
                for (size_t ti = 0; ti < cfg->num_blocks; ti++) {
                    if ((size_t)target >= cfg->blocks[ti].start && 
                        (size_t)target < cfg->blocks[ti].end) {
                        if (block->num_successors < 4) {
                            block->successors[block->num_successors++] = ti;
                        }
                        break;
                    }
                }
            }
            
            /*  Add fall-through */
            if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                block->successors[block->num_successors++] = bi + 1;
            }
        }
        else if (op == 0xE8) {
            /*  CALL  */
            if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                block->successors[block->num_successors++] = bi + 1;
            }
        }
        else if (op == 0xFF && last_inst.has_modrm) {
            /*  Indirect jump/call (FF /4 = JMP, FF /2 = CALL) */
            uint8_t reg = modrm_reg(last_inst.modrm);
            if (reg == 4 || reg == 5) {
                /*  Indirect JMP - mark as potential exit */
                block->is_exit = true;
            } else if (reg == 2 || reg == 3) {
                /*  Assume it returns */
                if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                    block->successors[block->num_successors++] = bi + 1;
                }
            }
        }
        else {
            if (bi + 1 < cfg->num_blocks && block->num_successors < 4) {
                block->successors[block->num_successors++] = bi + 1;
            }
        }
    }
    
    cfg->entry_block = 0;
    cfg->exit_block = cfg->num_blocks > 0 ? cfg->num_blocks - 1 : 0;
    
    free(leaders);
    
    DBG("Built CFG with %zu blocks\n", cfg->num_blocks);
    return cfg->num_blocks > 0;
#else
    /*  Fallback for unknown architectures */
    if (cfg) *cfg = (flowmap){0};
    return false;
#endif
}

#if defined(__aarch64__) || defined(_M_ARM64)
/* Flatten control flow for ARM64 currently just shuffles blocks */
static void flatline_flow_arm64(uint8_t *code, size_t size, flowmap *cfg, chacha_state_t *rng) {
    if (!code || !cfg || !rng || cfg->num_blocks < 3) return;
    if ((size % 4) != 0) return;
    
    shuffle_blocks_arm64(code, size, rng);
}
#endif

void flatline_flow(uint8_t *code, size_t size, flowmap *cfg, chacha_state_t *rng) {
#if defined(__aarch64__) || defined(_M_ARM64)
    flatline_flow_arm64(code, size, cfg, rng);
#elif defined(__x86_64__) || defined(_M_X64)
    if (!code || !cfg || !rng || cfg->num_blocks < 3) return;
    
    patch_t patch[64]; 
    size_t np = 0;
    size_t out = 0;
    size_t max_blocks = cfg->num_blocks;
    
    if (max_blocks > 0 && max_blocks > (SIZE_MAX - 128 - size) / 8) {
        return; /*  overflow */
    }
    
    size_t buf_sz = size + 128 + max_blocks * 8;
    uint8_t *nbuf = malloc(buf_sz);
    if (!nbuf) return;
    
    size_t *bmap = malloc(max_blocks * sizeof(size_t));
    if (!bmap) { free(nbuf); return; }
    
    size_t *order = malloc(max_blocks * sizeof(size_t));
    if (!order) { free(nbuf); free(bmap); return; }
    
    for (size_t i = 0; i < max_blocks; i++) order[i] = i;
    
    for (size_t i = max_blocks - 1; i > 0; i--) {
        size_t j = 1 + (chacha20_random(rng) % i); /*  keep block 0 pinned at index 0 */
        size_t t = order[i]; order[i] = order[j]; order[j] = t;
    }
    
    if (order[0] != 0) {
        size_t idx0 = 0;
        for (size_t k = 1; k < max_blocks; k++) { 
            if (order[k] == 0) { idx0 = k; break; } 
        }
        size_t t = order[0]; order[0] = order[idx0]; order[idx0] = t;
    }

    /*  Copy blocks and collect ALL control flow instructions for patching */
    for (size_t i = 0; i < max_blocks; i++) {
        size_t bi = order[i];
        blocknode *b = &cfg->blocks[bi];
        bmap[bi] = out;
        size_t blen = b->end - b->start;
        
        memcpy(nbuf + out, code + b->start, blen);

        /*  Scan entire block for control flow instructions  */
        size_t block_offset = 0;
        while (block_offset < blen && np < (sizeof(patch)/sizeof(patch[0]))) {
            x86_inst_t inst;
            if (!decode_x86_withme(nbuf + out + block_offset, blen - block_offset, 0, &inst, NULL) || 
                !inst.valid || inst.len == 0) {
                block_offset++;
                continue;
            }
            
            size_t instruction_addr_in_new_buffer = out + block_offset;
            uint64_t current_absolute_target = 0;
            bool should_patch = false;
            int patch_type = 0;

            if (inst.opcode[0] == 0xE8) {  /*  CALL rel32 */
                current_absolute_target = instruction_addr_in_new_buffer + inst.len + (int32_t)inst.imm;
                should_patch = true;
                patch_type = 2;
            } 
            else if (inst.opcode[0] == 0xE9) {  /*  JMP rel32 */
                current_absolute_target = instruction_addr_in_new_buffer + inst.len + (int32_t)inst.imm;
                should_patch = true;
                patch_type = 1;
            }
            else if (inst.opcode[0] == 0xEB) {  /*  JMP rel8 */
                current_absolute_target = instruction_addr_in_new_buffer + inst.len + (int8_t)inst.imm;
                should_patch = true;
                patch_type = 5;
            }
            else if (inst.opcode[0] >= 0x70 && inst.opcode[0] <= 0x7F) {  /*  Jcc rel8 */
                current_absolute_target = instruction_addr_in_new_buffer + inst.len + (int8_t)inst.imm;
                should_patch = true;
                patch_type = 3;
            } 
            else if (inst.opcode[0] == 0x0F && inst.opcode_len > 1 && 
                     inst.opcode[1] >= 0x80 && inst.opcode[1] <= 0x8F) {  /*  Jcc rel32 */
                current_absolute_target = instruction_addr_in_new_buffer + inst.len + (int32_t)inst.imm;
                should_patch = true;
                patch_type = 4;
            }

            if (should_patch) {
                patch[np].off = instruction_addr_in_new_buffer;
                patch[np].blki = bi;
                patch[np].abs_target = current_absolute_target;
                patch[np].inst_len = inst.len;
                patch[np].typ = patch_type;
                np++;
            }
            
            block_offset += inst.len;
        }
        
        out += blen;
    }

    for (size_t i = 0; i < np; i++) {
        patch_t *p = &patch[i];
        size_t src = p->off;

        size_t tgt_blk = (size_t)-1;
        for (size_t k = 0; k < max_blocks; k++) {
            if (p->abs_target >= cfg->blocks[k].start && p->abs_target < cfg->blocks[k].end) {
                tgt_blk = k;
                break;
            }
        }
        
        if (tgt_blk == (size_t)-1) {
            continue;
        }

        size_t new_tgt = bmap[tgt_blk];
        int32_t new_disp = 0;

        switch (p->typ) {
            case 1: /*  JMP rel32 (opcode E9) */
            case 2: /*  CALL rel32 (opcode E8) */
                if (src + 5 > buf_sz) continue;
                new_disp = (int32_t)(new_tgt - (src + 5));
                if (src + 1 + sizeof(int32_t) <= buf_sz) {
                    memcpy(nbuf + src + 1, &new_disp, sizeof(new_disp));
                }
                break;
                
            case 3: /*  Jcc rel8 (opcode 70-7F) */
                if (src + 2 > buf_sz) continue;
                new_disp = (int32_t)(new_tgt - (src + 2));
                
                if (new_disp >= -128 && new_disp <= 127 && src + 1 < buf_sz) {
                    nbuf[src + 1] = (uint8_t)new_disp;
                } else {
                    /*  Distance too far for rel8, expand to Jcc rel32 (0F 8x) */
                    if (src + 6 <= buf_sz) {
                        uint8_t cc = nbuf[src] & 0x0F;  /*  Extract condition code */
                        
                        /*  Shift instruction forward to make room */
                        memmove(nbuf + src + 6, nbuf + src + 2, buf_sz - src - 6);
                        
                        nbuf[src] = 0x0F;               /*  Two-byte opcode prefix */
                        nbuf[src + 1] = 0x80 | cc;      /*  Jcc rel32 */
                        new_disp = (int32_t)(new_tgt - (src + 6));
                        memcpy(nbuf + src + 2, &new_disp, 4);
                        
                        p->inst_len = 6;  /*  Update length */
                        out += 4;  /*  Account for expansion */
                    } else {
                        /*  Can't expand, rollback */
                        if (src < size && p->inst_len > 0 && src + p->inst_len <= size) {
                            memcpy(nbuf + src, code + cfg->blocks[p->blki].start + (src - bmap[p->blki]), p->inst_len);
                        }
                    }
                }
                break;
                
            case 4: /*  Jcc rel32 (opcode 0F 80-8F) */
                if (src + 6 > buf_sz) continue;
                new_disp = (int32_t)(new_tgt - (src + 6));
                if (src + 2 + sizeof(int32_t) <= buf_sz) {
                    memcpy(nbuf + src + 2, &new_disp, sizeof(new_disp));
                }
                break;
                
            case 5: /*  JMP rel8 (opcode EB) */
                if (src + 2 > buf_sz) continue;
                new_disp = (int32_t)(new_tgt - (src + 2));
                
                if (new_disp >= -128 && new_disp <= 127 && src + 1 < buf_sz) {
                    nbuf[src + 1] = (uint8_t)new_disp;
                } else {
                    /*  Distance too far for rel8, expand to JMP rel32 (E9) */
                    if (src + 5 <= buf_sz) {
                        /*  Shift instruction forward to make room */
                        memmove(nbuf + src + 5, nbuf + src + 2, buf_sz - src - 5);
                        
                        nbuf[src] = 0xE9;  /*  JMP rel32 */
                        new_disp = (int32_t)(new_tgt - (src + 5));
                        memcpy(nbuf + src + 1, &new_disp, 4);
                        
                        p->inst_len = 5;  /*  Update length */
                        out += 3;  /*  Account for expansion */
                    } else {
                        /*  Can't expand, rollback */
                        if (src < size && p->inst_len > 0 && src + p->inst_len <= size) {
                            memcpy(nbuf + src, code + cfg->blocks[p->blki].start + (src - bmap[p->blki]), p->inst_len);
                        }
                    }
                }
                break;
        }

        /*  Validate the patched instruction */
        if (src < buf_sz) {
            size_t remaining = buf_sz - src;
            x86_inst_t test_inst;
            if (!decode_x86_withme(nbuf + src, remaining > 16 ? 16 : remaining, 0, &test_inst, NULL) || !test_inst.valid) {
                /*  Rollback by restoring original bytes */
                if (src < size && p->inst_len > 0 && src + p->inst_len <= size) {
                    memcpy(nbuf + src, code + cfg->blocks[p->blki].start + (src - bmap[p->blki]), p->inst_len);
                }
            }
        }
    }

    /*  Decode all patched instructions */
    bool all_valid = true;
    for (size_t i = 0; i < np; i++) {
        patch_t *p = &patch[i];
        if (p->off >= buf_sz) {
            all_valid = false;
            break;
        }
        
        x86_inst_t inst;
        size_t remaining = buf_sz - p->off;
        if (!decode_x86_withme(nbuf + p->off, remaining > 16 ? 16 : remaining, 0, &inst, NULL) || 
            !inst.valid) {
            all_valid = false;
            break;
        }
    }

    /*  Only apply changes if all patches are valid */
    if (all_valid && out <= size) {
        memcpy(code, nbuf, out);
        if (out < size) memset(code + out, 0, size - out);
    }
    
    free(nbuf); 
    free(bmap); 
    free(order);
#else
    (void)code; (void)size; (void)cfg; (void)rng;
#endif
}

#if defined(__aarch64__) || defined(_M_ARM64)
/* Generate ARM64 trampoline for out-of-range branches loads 64-bit address into X16 then branches */
static inline void emit_trampoline_arm64(uint8_t *buf, size_t *off, uint64_t target, bool is_call) {
    if (!buf || !off) return;
    
    *(uint32_t*)(buf + *off) = 0xD2800000 | (1u << 31) | 16 | ((target & 0xFFFF) << 5);
    *off += 4;
    
    *(uint32_t*)(buf + *off) = 0xF2A00000 | (1u << 31) | 16 | (((target >> 16) & 0xFFFF) << 5);
    *off += 4;
    
    *(uint32_t*)(buf + *off) = 0xF2C00000 | (1u << 31) | 16 | (((target >> 32) & 0xFFFF) << 5);
    *off += 4;
    
    if (is_call) {
        *(uint32_t*)(buf + *off) = 0xD63F0200;
    } else {
        *(uint32_t*)(buf + *off) = 0xD61F0200;
    }
    *off += 4;
}

/* Reorder ARM64 basic blocks and fix up all branch instructions */
static void shuffle_blocks_arm64(uint8_t *code, size_t size, chacha_state_t *rng) {
    if (!code || !rng || size < 8 || (size % 4) != 0) return;
    
    flowmap cfg;
    if (!sketch_flow_arm64(code, size, &cfg)) return;
    if (cfg.num_blocks < 2) { free(cfg.blocks); return; }

    size_t nb = cfg.num_blocks;
    size_t *order = malloc(nb * sizeof(size_t));
    if (!order) { free(cfg.blocks); return; }
    
    for (size_t i = 0; i < nb; i++) order[i] = i;
    for (size_t i = nb - 1; i > 1; i--) {
        size_t j = 1 + (chacha20_random(rng) % i);
        size_t t = order[i]; order[i] = order[j]; order[j] = t;
    }

    size_t nbuf_size = size * 2;
    uint8_t *nbuf = malloc(nbuf_size);
    if (!nbuf) { free(order); free(cfg.blocks); return; }
    
    size_t *new_off = malloc(nb * sizeof(size_t));
    if (!new_off) { free(order); free(nbuf); free(cfg.blocks); return; }
    
    size_t out = 0;
    for (size_t oi = 0; oi < nb; oi++) {
        size_t bi = order[oi];
        blocknode *b = &cfg.blocks[bi];
        size_t blen = b->end - b->start;
        
        if (out + blen > nbuf_size) break;
        memcpy(nbuf + out, code + b->start, blen);
        new_off[bi] = out;
        out += blen;
    }

    /* Fix up all branch instructions */
    for (size_t oi = 0; oi < nb; oi++) {
        size_t bi = order[oi];
        blocknode *b = &cfg.blocks[bi];
        size_t blen = b->end - b->start;
        size_t block_new_offset = new_off[bi];
        
        for (size_t off = 0; off + 4 <= blen; off += 4) {
            size_t abs_off = block_new_offset + off;
            if (abs_off + 4 > out) break;
            
            arm64_inst_t inst;
            if (!decode_arm64(nbuf + abs_off, &inst) || !inst.valid) continue;
            
            if (!inst.is_control_flow) continue;
            
            size_t old_offset = b->start + off;
            int64_t old_target = old_offset + inst.target;
            
            size_t tgt_block = SIZE_MAX;
            for (size_t k = 0; k < nb; k++) {
                if (old_target >= (int64_t)cfg.blocks[k].start && 
                    old_target < (int64_t)cfg.blocks[k].end) {
                    tgt_block = k;
                    break;
                }
            }
            
            if (tgt_block == SIZE_MAX) continue;
            
            size_t new_target = new_off[tgt_block];
            int64_t new_disp = (int64_t)new_target - (int64_t)(abs_off + 4);
            
            bool fixed = false;
            
            if (inst.type == ARM_OP_BRANCH || inst.type == ARM_OP_BRANCH_LINK) {
                int64_t max_range = (1LL << 27);
                if (new_disp >= -max_range && new_disp < max_range && (new_disp % 4) == 0) {
                    uint32_t new_insn = inst.raw & 0xFC000000;
                    uint32_t imm26 = ((new_disp / 4) & 0x3FFFFFF);
                    new_insn |= imm26;
                    *(uint32_t*)(nbuf + abs_off) = new_insn;
                    fixed = true;
                }
            } else if (inst.type == ARM_OP_BRANCH_COND || inst.type == ARM_OP_CBZ || 
                       inst.type == ARM_OP_CBNZ) {
                int64_t max_range = (1LL << 20);
                if (new_disp >= -max_range && new_disp < max_range && (new_disp % 4) == 0) {
                    uint32_t new_insn = inst.raw & 0xFF00001F;
                    uint32_t imm19 = ((new_disp / 4) & 0x7FFFF) << 5;
                    new_insn |= imm19;
                    *(uint32_t*)(nbuf + abs_off) = new_insn;
                    fixed = true;
                }
            } else if (inst.type == ARM_OP_TBZ || inst.type == ARM_OP_TBNZ) {
                int64_t max_range = (1LL << 15);
                if (new_disp >= -max_range && new_disp < max_range && (new_disp % 4) == 0) {
                    uint32_t new_insn = inst.raw & 0xFFF8001F;
                    uint32_t imm14 = ((new_disp / 4) & 0x3FFF) << 5;
                    new_insn |= imm14;
                    *(uint32_t*)(nbuf + abs_off) = new_insn;
                    fixed = true;
                }
            }
        }
    }
    size_t final_size = out;
    if (final_size <= size) {
        memcpy(code, nbuf, final_size);
        if (final_size < size) memset(code + final_size, 0, size - final_size);
    }

    free(order);
    free(new_off);
    free(nbuf);
    free(cfg.blocks);
}
#endif  // __aarch64__ || _M_ARM64

#if defined(__x86_64__) || defined(_M_X64)
/* Generate x86-64 trampoline mov rax, imm64 ; jmp/call rax */
static inline void emit_trampoline(uint8_t *buf, size_t *off, uint64_t target, bool is_call) {
    if (!buf || !off) return;
    
    buf[(*off)++] = 0x48; buf[(*off)++] = 0xB8;
    memcpy(buf + *off, &target, 8);
    *off += 8;
    if (is_call) { buf[(*off)++] = 0xFF; buf[(*off)++] = 0xD0; }
    else         { buf[(*off)++] = 0xFF; buf[(*off)++] = 0xE0; }
}

void shuffle_blocks(uint8_t *code, size_t size, void *rng) {
    if (!code || !rng) return;
    
#if defined(__aarch64__) || defined(_M_ARM64)
    shuffle_blocks_arm64(code, size, (chacha_state_t*)rng);
    return;
#elif defined(__x86_64__) || defined(_M_X64)
    flowmap cfg;
    if (!sketch_flow(code, size, &cfg)) return;
    if (cfg.num_blocks < 2) { free(cfg.blocks); return; }

    size_t nb = cfg.num_blocks;
    size_t *order = malloc(nb * sizeof(size_t));
    if (!order) { free(cfg.blocks); return; }
    
    for (size_t i=0;i<nb;i++) order[i]=i;
    for (size_t i=nb-1;i>1;i--) {
        size_t j = 1 + (chacha20_random(rng)%i);
        size_t t=order[i]; order[i]=order[j]; order[j]=t;
    }

    if (size > SIZE_MAX / 2) { free(order); free(cfg.blocks); return; }
    
    uint8_t *nbuf = malloc(size * 2);
    if (!nbuf) { free(order); free(cfg.blocks); return; }
    
    size_t *new_off = malloc(nb * sizeof(size_t));
    if (!new_off) { free(order); free(nbuf); free(cfg.blocks); return; }
    
    size_t out=0;
    for (size_t oi=0; oi<nb; oi++) {
        size_t bi=order[oi];
        blocknode *b=&cfg.blocks[bi];
        size_t blen=b->end-b->start;
        memcpy(nbuf+out, code+b->start, blen);
        new_off[bi]=out;
        out+=blen;
    }

    size_t tramp_base = out;
    size_t tramp_off = tramp_base;

    for (size_t oi=0; oi<nb; oi++) {
        size_t bi=order[oi];
        blocknode *b=&cfg.blocks[bi];
        size_t blen=b->end-b->start;
        size_t off=new_off[bi];
        size_t cur=0;
        while (cur<blen) {
            x86_inst_t inst;
            if (!decode_x86_withme(nbuf+off+cur, blen-cur, 0, &inst, NULL) || !inst.valid) { cur++; continue; }
            size_t inst_off = off+cur;
            int typ=0;
            if (inst.opcode[0]==0xE8) typ=2;
            else if (inst.opcode[0]==0xE9) typ=1;
            else if (inst.opcode[0]==0xEB) typ=5;
            else if (inst.opcode[0]>=0x70 && inst.opcode[0]<=0x7F) typ=3;
            else if (inst.opcode[0]==0x0F && inst.opcode_len>1 && inst.opcode[1]>=0x80) typ=4;
            if (!typ) { cur+=inst.len; continue; }

            int64_t oldtgt=0;
            if (typ==1||typ==2) oldtgt=inst_off+inst.len+(int32_t)inst.imm;
            else if (typ==3||typ==5) oldtgt=inst_off+inst.len+(int8_t)inst.imm;
            else if (typ==4) oldtgt=inst_off+inst.len+(int32_t)inst.imm;

            size_t tgt_blk=SIZE_MAX;
            for (size_t k=0;k<nb;k++) {
                if (oldtgt>=cfg.blocks[k].start && oldtgt<cfg.blocks[k].end) { tgt_blk=k; break; }
            }

            if (tgt_blk!=SIZE_MAX) {
                int32_t rel=0;
                size_t tgt=new_off[tgt_blk];
                if (typ==1||typ==2) { rel=(int32_t)(tgt-(inst_off+inst.len)); memcpy(nbuf+inst_off+1,&rel,4); }
                else if (typ==3||typ==5) {
                    int32_t d=(int32_t)(tgt-(inst_off+inst.len));
                    if (d>=-128 && d<=127) nbuf[inst_off+1]=(uint8_t)d;
                    else {
                        if (typ==3) { uint8_t cc=nbuf[inst_off]&0x0F; nbuf[inst_off]=0x0F; nbuf[inst_off+1]=0x80|cc; rel=(int32_t)(tgt-(inst_off+6)); memcpy(nbuf+inst_off+2,&rel,4); }
                        else { nbuf[inst_off]=0xE9; rel=(int32_t)(tgt-(inst_off+5)); memcpy(nbuf+inst_off+1,&rel,4); }
                    }
                }
                else if (typ==4) { rel=(int32_t)(tgt-(inst_off+inst.len)); memcpy(nbuf+inst_off+2,&rel,4); }
            } else {
                /*  Jump target is outside our blocks  */
                bool is_call=(typ==2);
                size_t tramp_start = tramp_off;
                emit_trampoline(nbuf,&tramp_off,(uint64_t)oldtgt,is_call);
                /*   48 B8 (imm64) FF E0/D0 */
                size_t tramp_loc = tramp_start;
                
                int32_t rel=(int32_t)(tramp_loc-(inst_off+ (typ==2||typ==1?5:2)));
                if (typ==2||typ==1) { 
                    nbuf[inst_off]=is_call?0xE8:0xE9; 
                    memcpy(nbuf+inst_off+1,&rel,4); 
                }
                else if (typ==3) { 
                    /*  Expand Jcc rel8 to Jcc rel32 */
                    uint8_t cc=nbuf[inst_off]&0x0F; 
                    nbuf[inst_off]=0x0F; 
                    nbuf[inst_off+1]=0x80|cc; 
                    rel=(int32_t)(tramp_loc-(inst_off+6)); 
                    memcpy(nbuf+inst_off+2,&rel,4); 
                }
                else if (typ==4) { 
                    rel=(int32_t)(tramp_loc-(inst_off+6)); 
                    memcpy(nbuf+inst_off+2,&rel,4); 
                }
                else if (typ==5) { 
                    /*  Expand JMP rel8 to JMP rel32 */
                    nbuf[inst_off]=0xE9; 
                    rel=(int32_t)(tramp_loc-(inst_off+5)); 
                    memcpy(nbuf+inst_off+1,&rel,4); 
                }
            }
            cur+=inst.len;
        }
    }

    size_t final_size=tramp_off;
    if (final_size<=size) {
        memcpy(code,nbuf,final_size);
        if (final_size<size) memset(code+final_size,0,size-final_size);
    }

    free(order); free(new_off); free(nbuf); free(cfg.blocks);
#else
    (void)code; (void)size; (void)rng; /*  no idea  */
#endif
}

static inline bool is_control_flow(const x86_inst_t *i) { 
    if (!i) return false;
    uint8_t op = i->opcode[0];
    if (op == 0xE8 || op == 0xE9 || op == 0xEB) return true; /*  call/jmp/shortjmp */
    if (op == 0xC3 || op == 0xCB || op == 0xC2 || op == 0xCA) return true; /*  ret */
    if (op == 0xE0 || op == 0xE1 || op == 0xE2 || op == 0xE3) return true;
    if (op == 0xFF) return true;
    return false;
}

static inline uint16_t inst_reg_mask(const x86_inst_t *i) {
    if (!i) return 0;
    
    uint16_t m = 0;
    if (i->has_modrm) {
        uint8_t r = modrm_reg(i->modrm) & 7;
        uint8_t rm = modrm_rm(i->modrm) & 7;
        m |= (1u << r) | (1u << rm);
    }
    uint8_t op = i->opcode[0];
    if ((op & 0xF8) == 0xB8) { /*  mov reg, imm -> writes reg */
        uint8_t reg = op & 0x7;
        m |= (1u << reg);
    }
    if ((op & 0xF8) == 0x50) { /*  push/pop family touches reg (and rsp) */
        uint8_t reg = op & 0x7;
        m |= (1u << reg);
    }
    if ((op & 0xF8) == 0x40) {
        uint8_t reg = op & 0x7;
        m |= (1u << reg);
    }
    if (i->has_modrm && (op == 0x83 || op == 0x81 || op == 0x69 || op == 0x6B)) {
        uint8_t rm = modrm_rm(i->modrm) & 7;
        m |= (1u << rm);
    }
    return m;
}

static inline bool has_memory_access(const x86_inst_t *i) {
    if (!i || !i->has_modrm) return false;
    uint8_t mod = (i->modrm >> 6) & 3;
    return mod != 3;  /*  mod != 11 means memory operand */
}

static inline bool independent_inst(const x86_inst_t *a, const x86_inst_t *b) {
    if (!a || !b) return false;
    if (is_control_flow(a) || is_control_flow(b)) return false;
    
    /*  Check register dependencies */
    uint16_t ma = inst_reg_mask(a);
    uint16_t mb = inst_reg_mask(b);
    if (ma & mb) return false;
    
    /*  if both access memory, assume dependent */
    if (has_memory_access(a) && has_memory_access(b)) return false;
    
    /*  If one writes memory and other reads/writes memory, assume dependent */
    if (has_memory_access(a) || has_memory_access(b)) {
        /*  Check if either is a store (MOV to memory, ...) */
        uint8_t op_a = a->opcode[0];
        uint8_t op_b = b->opcode[0];
        if ((op_a == 0x89 || op_a == 0x88 || op_a == 0xC7) ||  /*  Stores */
            (op_b == 0x89 || op_b == 0x88 || op_b == 0xC7)) {
            return false;  /*  Assume  */
        }
    }
    
    return true;
}

static inline bool swap_adjacent_ranges(uint8_t *code, size_t size, size_t a_off, size_t a_len, size_t b_len) {
    if (a_off + a_len + b_len > size) return false;
    uint8_t *tmp = (uint8_t*)malloc(a_len);
    if (!tmp) return false;
    memcpy(tmp, code + a_off, a_len);
    memmove(code + a_off, code + a_off + a_len, b_len); /*  move B forward into A's crib */
    memcpy(code + a_off + b_len, tmp, a_len);
    free(tmp);
    return true;
}

static int build_instr_win(uint8_t *code, size_t size, size_t offset,  /*  long ass name  */
                                   x86_inst_t *win, size_t *win_offs, int max_window) {
    if (!code || !win || !win_offs) return 0;
    
    int win_cnt = 0;
    size_t scan = offset;

    while (scan < size && win_cnt < max_window) {
        x86_inst_t inst;
        if (!decode_x86_withme(code + scan, size - scan, 0, &inst, NULL) || 
            !inst.valid || inst.len == 0 || scan + inst.len > size) {
            scan++;
            continue;
        }
        win[win_cnt] = inst;
        win_offs[win_cnt] = scan;
        win_cnt++;
        scan += inst.len;
        if (is_control_flow(&inst)) break;
    }
    return win_cnt;
}

static void win_reorder(uint8_t *code, size_t size, x86_inst_t *win, 
                                     size_t *win_offs, int win_cnt, chacha_state_t *rng,
                                     unsigned mutation_intensity, muttt_t *log, unsigned gen) {
    if (!code || !win || !win_offs || !rng) return;
    
    for (int i = 0; i + 1 < win_cnt; ++i) {
        size_t a_off = win_offs[i];
        size_t a_len = win[i].len;
        size_t b_off = win_offs[i+1];
        size_t b_len = win[i+1].len;
        
        if (b_off != a_off + a_len) {
            continue;
        }
        
        if (independent_inst(&win[i], &win[i+1])) {
            if ((chacha20_random(rng) % 10) < (mutation_intensity / 2 + 1)) {
                if (swap_adjacent_ranges(code, size, a_off, a_len, b_len)) {
                    win_offs[i] = a_off;
                    win_offs[i+1] = a_off + b_len;
                }
            }
        }
    }
}

#if defined(__aarch64__) || defined(_M_ARM64)
/* Apply ARM64-specific mutations register substitution, equivalences, expansions */
void scramble_arm64(uint8_t *code, size_t size, chacha_state_t *rng, unsigned gen,
                    muttt_t *log, liveness_state_t *liveness, unsigned mutation_intensity) {
    if (!code || !rng || size < 4) return;
    
    size_t offset = 0;
    size_t changes = 0;
    size_t max_changes = (size / 4) / 10 + 1;
    
    if (liveness) boot_live(liveness);
    
    while (offset + 4 <= size && changes < max_changes) {
        arm64_inst_t inst;
        if (!decode_arm64(code + offset, &inst) || !inst.valid) {
            offset += 4;
            continue;
        }
        
        if (liveness) pulse_live(liveness, offset, &inst);
        
        bool mutated = false;
        uint32_t backup = inst.raw;
        
        if (!mutated && gen >= 3 && (chacha20_random(rng) % 100) < (mutation_intensity * 5)) {
            size_t temp_size = size;
            if (apply_arm64_expansion(code, &temp_size, size * 2, offset, &inst, liveness, rng)) {
                size_t expansion_len = temp_size - size;
                size = temp_size;
                mutated = true;
                changes++;
                if (log) drop_mut(log, offset, expansion_len + 4, MUT_EXPAND, gen, "arm64 expand");
                
                offset += expansion_len + 4;
                continue;
            }
        }
        
        if (inst.ring0 || inst.is_control_flow) {
            offset += 4;
            continue;
        }
        
        /* Register substitution */
        if (!mutated && liveness && (chacha20_random(rng) % 100) < (mutation_intensity * 10)) {
            bool can_substitute = false;
            uint8_t new_rd = inst.rd;
            uint8_t new_rn = inst.rn;
            uint8_t new_rm = inst.rm;
            
            if (inst.type == ARM_OP_MOV || inst.type == ARM_OP_ADD || 
                inst.type == ARM_OP_SUB || inst.type == ARM_OP_AND ||
                inst.type == ARM_OP_ORR || inst.type == ARM_OP_EOR) {
                
                if (inst.rd < 29 && cool_tmutation(inst.rd)) {
                    new_rd = jack_reg(liveness, inst.rd, offset, rng);
                    if (new_rd != inst.rd) can_substitute = true;
                }
                
                if (inst.rm < 32 && inst.rm < 29 && cool_tmutation(inst.rm)) {
                    new_rm = jack_reg(liveness, inst.rm, offset, rng);
                    if (new_rm != inst.rm) can_substitute = true;
                }
            }
            
            if (can_substitute) {
                uint32_t new_insn = inst.raw;
                new_insn = (new_insn & ~0x1F) | (new_rd & 0x1F);
                if (inst.rm < 32) {
                    new_insn = (new_insn & ~(0x1F << 16)) | ((new_rm & 0x1F) << 16);
                }
                
                arm64_inst_t test;
                uint8_t test_buf[4];
                *(uint32_t*)test_buf = new_insn;
                if (decode_arm64(test_buf, &test) && test.valid && !test.ring0) {
                    *(uint32_t*)(code + offset) = new_insn;
                    mutated = true;
                    changes++;
                    if (log) drop_mut(log, offset, 4, MUT_REG, gen, "arm64 reg subst");
                }
            }
        }
        
        /* MOV equivalents */
        if (!mutated && inst.type == ARM_OP_MOV && (chacha20_random(rng) % 100) < (mutation_intensity * 8)) {
            /*  MOV Xd, Xm > ORR Xd, XZR, Xm */
            if (inst.rd < 29 && inst.rm < 29) {
                uint32_t new_insn = 0xAA0003E0;  /*  ORR base encoding */
                new_insn |= (inst.is_64bit ? (1u << 31) : 0);
                new_insn |= (inst.rd & 0x1F);
                new_insn |= ((inst.rm & 0x1F) << 16);
                new_insn |= (31 << 5);  /*  Rn = XZR */
                
                *(uint32_t*)(code + offset) = new_insn;
                mutated = true;
                changes++;
                if (log) drop_mut(log, offset, 4, MUT_EQUIV, gen, "mov->orr");
            }
        }
        
        /*  Zero Reg  */
        if (!mutated && inst.type == ARM_OP_MOV && inst.imm == 0 && 
            (chacha20_random(rng) % 100) < (mutation_intensity * 8)) {
            
            switch (chacha20_random(rng) % 4) {
                case 0: {  /*  MOV Xd, #0 > EOR Xd, Xd, Xd */
                    uint32_t new_insn = 0xCA000000;
                    new_insn |= (inst.is_64bit ? (1u << 31) : 0);
                    new_insn |= (inst.rd & 0x1F);
                    new_insn |= ((inst.rd & 0x1F) << 5);
                    new_insn |= ((inst.rd & 0x1F) << 16);
                    *(uint32_t*)(code + offset) = new_insn;
                    mutated = true;
                    break;
                }
                case 1: {  /*  MOV Xd, #0 > SUB Xd, Xd, Xd */
                    uint32_t new_insn = 0xCB000000;
                    new_insn |= (inst.is_64bit ? (1u << 31) : 0);
                    new_insn |= (inst.rd & 0x1F);
                    new_insn |= ((inst.rd & 0x1F) << 5);
                    new_insn |= ((inst.rd & 0x1F) << 16);
                    *(uint32_t*)(code + offset) = new_insn;
                    mutated = true;
                    break;
                }
                case 2: {  /*  MOV Xd, #0 > AND Xd, Xd, #0 */
                    uint32_t new_insn = 0x92400000;
                    new_insn |= (inst.is_64bit ? (1u << 31) : 0);
                    new_insn |= (inst.rd & 0x1F);
                    new_insn |= ((inst.rd & 0x1F) << 5);
                    *(uint32_t*)(code + offset) = new_insn;
                    mutated = true;
                    break;
                }
                case 3: {  /*  MOV Xd, #0 > MOVZ Xd, #0 */
                    uint32_t new_insn = 0xD2800000;
                    new_insn |= (inst.is_64bit ? (1u << 31) : 0);
                    new_insn |= (inst.rd & 0x1F);
                    *(uint32_t*)(code + offset) = new_insn;
                    mutated = true;
                    break;
                }
            }
            
            if (mutated) {
                changes++;
                if (log) drop_mut(log, offset, 4, MUT_EQUIV, gen, "zero equiv");
            }
        }
        
        /*  ADD/SUB Equivalents */
        if (!mutated && (inst.type == ARM_OP_ADD || inst.type == ARM_OP_SUB) && 
            inst.imm == 0 && (chacha20_random(rng) % 100) < (mutation_intensity * 6)) {
            
            /*  ADD Xd, Xn, #0 > MOV Xd, Xn (ORR Xd, XZR, Xn) */
            if (inst.type == ARM_OP_ADD && inst.rd < 29 && inst.rn < 29) {
                uint32_t new_insn = 0xAA0003E0;
                new_insn |= (inst.is_64bit ? (1u << 31) : 0);
                new_insn |= (inst.rd & 0x1F);
                new_insn |= ((inst.rn & 0x1F) << 16);
                new_insn |= (31 << 5);  /*  Rn = XZR */
                *(uint32_t*)(code + offset) = new_insn;
                mutated = true;
                changes++;
                if (log) drop_mut(log, offset, 4, MUT_EQUIV, gen, "add0->mov");
            }
        }
        
        /*  CMP/CMN Equi */
        if (!mutated && inst.type == ARM_OP_CMP && inst.imm == 0 &&
            (chacha20_random(rng) % 100) < (mutation_intensity * 5)) {
            
            /*  CMP Xn, #0 > SUBS XZR, Xn, #0 */
            /*  Already in, we can swap to CMN tho! */
            /*  CMP Xn, #0 ≡ CMN Xn, #0 (for zero) */
            uint32_t new_insn = 0xB1000000;  /*  CMN (adds) base */
            new_insn |= (inst.is_64bit ? (1u << 31) : 0);
            new_insn |= (31);  /*  Rd = XZR */
            new_insn |= ((inst.rn & 0x1F) << 5);
            *(uint32_t*)(code + offset) = new_insn;
            mutated = true;
            changes++;
            if (log) drop_mut(log, offset, 4, MUT_EQUIV, gen, "cmp->cmn");
        }
        
        /*  NOP Insertion (if space allows) */
        if (!mutated && (chacha20_random(rng) % 100) < (mutation_intensity * 3)) {
            /*  Insert NOP before current instruction  */
            /*  For now, replace current instruction with NOP if it's cool */
            if (inst.type == ARM_OP_NOP || 
                (inst.type == ARM_OP_MOV && inst.rd == inst.rm)) {
                *(uint32_t*)(code + offset) = 0xD503201F;  /*  NOP */
                mutated = true;
                changes++;
                if (log) drop_mut(log, offset, 4, MUT_JUNK, gen, "nop");
            }
        }
        
        /*  Validate mutation */
        if (mutated) {
            arm64_inst_t verify;
            if (!decode_arm64(code + offset, &verify) || !verify.valid || verify.ring0) {
                /*  Rollback */
                *(uint32_t*)(code + offset) = backup;
                changes--;
            }
        }
        
        offset += 4;
    }
}
#endif  // __aarch64__ || _M_ARM64

void scramble_x86(uint8_t *code, size_t size, chacha_state_t *rng, unsigned gen,
                        muttt_t *log, liveness_state_t *liveness, unsigned mutation_intensity) {
    if (!code || !rng) return;
    
    size_t offset = 0;

    if (liveness) boot_live(liveness);

    /*  Apply mutation chains early in the pipeline (gen 5+) */
    if (gen >= 5 && (chacha20_random(rng) % 10) < (gen > 10 ? 6 : 3)) {
        unsigned chain_depth = 1 + (gen / 10);  
        if (chain_depth > 3) chain_depth = 3;   /*  Ka-Boom */
        
        size_t new_size = expand_with_chains(code, size, size * 2, liveness, rng, 
                                             chain_depth, mutation_intensity * 2);
        if (new_size > size && new_size <= size * 2) {
            if (log) drop_mut(log, 0, new_size, MUT_EXPAND, gen, "chain expand");
            /*  Note: size parameter is const, so we can't update it here */
            /*  when called needs to handle size changes */
        }
    }

    while (offset < size) {
        const int WINDOW_MAX = 8;
        x86_inst_t win[WINDOW_MAX];
        size_t win_offs[WINDOW_MAX];
        
        int win_cnt = build_instr_win(code, size, offset, win, win_offs, WINDOW_MAX);
        
        win_reorder(code, size, win, win_offs, win_cnt, rng, 
                                mutation_intensity, log, gen);

        x86_inst_t inst;
        if (!decode_x86_withme(code + offset, size - offset, 0, &inst, NULL) || !inst.valid || inst.len == 0 || offset + inst.len > size) {
            offset++;
            continue;
        }

        if (liveness) pulse_live(liveness, offset, &inst);

        /* Skip indirect calls/jumps - used by dlsym, constructors, vtables */
        bool is_indirect_call = false;
        if (inst.has_modrm) {
            uint8_t mod = (inst.modrm >> 6) & 3;
            if (inst.opcode[0] == 0xFF && (mod != 0 || inst.has_sib)) {
                uint8_t reg = modrm_reg(inst.modrm);
                if (reg == 2 || reg == 4) {
                    is_indirect_call = true;
                }
            }
        }
        
        if (is_indirect_call) {
            offset += inst.len;
            continue;
        }

        if ((chacha20_random(rng) % 100) < (mutation_intensity * 3)) {
            size_t temp_size = size;
            if (apply_expansion(code, &temp_size, offset, &inst, liveness, rng)) {
                x86_inst_t new_inst;
                if (decode_x86_withme(code + offset, size - offset, 0, &new_inst, NULL) && new_inst.valid) {
                    if (log) drop_mut(log, offset, new_inst.len, MUT_EXPAND, gen, "inst expand");
                    offset += new_inst.len;
                    continue;
                }
            }
        }

        bool mutated = false;

        if (inst.has_modrm && inst.len <= 8 && inst.len >= 2) {
            uint8_t reg = modrm_reg(inst.modrm);
            uint8_t rm = modrm_rm(inst.modrm);
            uint8_t mod = (inst.modrm >> 6) & 3;
            
            if (reg == 4 || reg == 5 || rm == 4 || rm == 5) {
                goto skip;
            }
            
            /* Only mutate MOV-like instructions, not arithmetic/shifts */
            bool is_safe_opcode = (inst.opcode[0] >= 0x88 && inst.opcode[0] <= 0x8F);
            
            /* Only substitute in reg-to-reg ops (mod==3) */
            if (mod == 3 && liveness && is_safe_opcode) {
                uint8_t new_reg = jack_reg(liveness, reg, offset, rng);
                uint8_t new_rm = jack_reg(liveness, rm, offset, rng);
                
                if (is_stackp(new_reg) || is_stackp(new_rm)) {
                    goto skip;
                }
                
                if (new_reg == reg && new_rm == rm) {
                    goto skip;
                }
                
                if (!has_implicit_rsp_use(inst.opcode[0]) &&
                    (inst.opcode[0] & 0xF8) != 0x50 && 
                    (inst.opcode[0] & 0xF8) != 0x58) {
                    
                    uint8_t temp_modrm = (inst.modrm & 0xC0) | (new_reg << 3) | new_rm;
                    
                    /* Find ModRM byte: after prefixes + REX + opcode */
                    size_t modrm_pos_in_raw = 0;
                    modrm_pos_in_raw += inst.prefixes;
                    if (inst.rex) modrm_pos_in_raw++;
                    modrm_pos_in_raw += inst.opcode_len;
                    
                    if (modrm_pos_in_raw >= inst.len || modrm_pos_in_raw >= 15) {
                        goto skip;
                    }
                    
                    if (inst.raw[modrm_pos_in_raw] != inst.modrm) {
                        goto skip;
                    }
                    
                    size_t modrm_offset = offset + modrm_pos_in_raw;
                    
                    if (modrm_offset < size) {
                        uint8_t orig_byte = code[modrm_offset];
                        code[modrm_offset] = temp_modrm;
                        
                        x86_inst_t verify;
                        if (decode_x86_withme(code + offset, size - offset, 0, &verify, NULL) &&
                            verify.valid && 
                            !verify.ring0 &&
                            verify.has_modrm &&
                            verify.len == inst.len &&
                            verify.opcode[0] == inst.opcode[0] &&
                            ((verify.modrm >> 6) & 3) == 3) {
                            mutated = true;
                        } else {
                            code[modrm_offset] = orig_byte;
                        }
                    }
                }
            }
        }
        skip:
        if (!mutated) {
            /* XOR reg,reg equivalence - only reg-to-reg (mod==3) */
            if (inst.opcode[0] == 0x31 && inst.has_modrm && modrm_reg(inst.modrm) == modrm_rm(inst.modrm)) {
                uint8_t mod = (inst.modrm >> 6) & 3;
                uint8_t reg = modrm_reg(inst.modrm);
                
                if (mod == 3) {
                    if (chacha20_random(rng) % 2) {
                        code[offset] = 0x29;
                    } else {
                        code[offset] = 0xB8 + reg;
                        if (offset + 5 <= size) memset(code + offset + 1, 0, 4);
                    }
                    if (!is_op_ok(code + offset)) {
                        if (offset + inst.len <= size && inst.len > 0) memcpy(code + offset, inst.raw, inst.len);
                    } else {
                        mutated = true;
                    }
                }
            }
            else if ((inst.opcode[0] & 0xF8) == 0xB8 && inst.imm == 0) {
                uint8_t reg = inst.opcode[0] & 0x7;
                size_t new_len = 0;
                
                switch(chacha20_random(rng) % 3) {
                    case 0:
                        code[offset] = 0x31;
                        code[offset+1] = 0xC0 | (reg << 3) | reg;
                        new_len = 2;
                        break;
                    case 1:
                        code[offset] = 0x83;
                        code[offset+1] = 0xE0 | reg;
                        code[offset+2] = 0x00;
                        new_len = 3;
                        break;
                    case 2:
                        code[offset] = 0x29;
                        code[offset+1] = 0xC0 | (reg << 3) | reg;
                        new_len = 2;
                        break;
                }
                
                if (new_len < inst.len && offset + inst.len <= size) {
                    memset(code + offset + new_len, 0x90, inst.len - new_len);
                }
                
                if (!is_op_ok(code + offset)) {
                    if (offset + inst.len <= size && inst.len > 0) memcpy(code + offset, inst.raw, inst.len);
                } else mutated = true;
            }
            else if (inst.opcode[0] == 0x83 && inst.has_modrm && inst.raw[2] == 0x01) {
                uint8_t reg = modrm_rm(inst.modrm);
                uint8_t mod = (inst.modrm >> 6) & 3;
                
                if (mod == 3 && offset + 3 <= size) {
                    if (chacha20_random(rng) % 2) {
                        code[offset] = 0x48;
                        code[offset+1] = 0xFF;
                        code[offset+2] = 0xC0 | reg;
                        if (offset + 3 < size && inst.len > 3) {
                            size_t fill_len = (inst.len - 3 < size - offset - 3) ? inst.len - 3 : size - offset - 3;
                            if (fill_len > 0) memset(code + offset + 3, 0x90, fill_len);
                        }
                    } else {
                        if (offset + 4 <= size) {
                            code[offset] = 0x48;
                            code[offset+1] = 0x8D;
                            code[offset+2] = 0x40 | (reg << 3) | reg;
                            code[offset+3] = 0x01;
                            if (offset + 4 < size && inst.len > 4) {
                                size_t fill_len = (inst.len - 4 < size - offset - 4) ? inst.len - 4 : size - offset - 4;
                                if (fill_len > 0) memset(code + offset + 4, 0x90, fill_len);
                            }
                        }
                    }
                    if (!is_op_ok(code + offset)) {
                        if (offset + inst.len <= size && inst.len > 0) memcpy(code + offset, inst.raw, inst.len);
                    } else mutated = true;
                }
            }
            else if (inst.opcode[0] == 0x8D && inst.has_modrm) {
                uint8_t reg = modrm_reg(inst.modrm);
                uint8_t rm = modrm_rm(inst.modrm);
                uint8_t mod = (inst.modrm >> 6) & 3;
                
                if (reg == rm && inst.disp == 0 && !inst.has_sib && mod != 0) {
                    code[offset] = 0x89;
                    if (!is_op_ok(code + offset)) code[offset] = 0x8D;
                    else mutated = true;
                }
            }
            else if (inst.opcode[0] == 0x85 && inst.has_modrm) {
                uint8_t reg = modrm_reg(inst.modrm);
                uint8_t rm = modrm_rm(inst.modrm);
                if (reg == rm) {
                    code[offset] = 0x39;
                    if (!is_op_ok(code + offset)) code[offset] = 0x85;
                    else mutated = true;
                }
            }
        }

        if (!mutated && (chacha20_random(rng) % 10) < mutation_intensity) {
            bool cool_to_insert = true; /*  PAUSE!! */
            if (liveness) {
                const uint8_t opaque_regs[] = {0, 1, 2, 6, 7};
                for (size_t i = 0; i < sizeof(opaque_regs); i++) {
                    if (liveness->regs[opaque_regs[i]].iz_live) {
                        cool_to_insert = false;
                        break;
                    }
                }
            }
            
            if (cool_to_insert) {
                uint8_t opq_buf[64];
                size_t opq_len;
                uint32_t target_value = chacha20_random(rng);
                forge_ghost(opq_buf, &opq_len, target_value, rng);

                uint8_t junk_buf[32];
                size_t junk_len;
                spew_trash(junk_buf, &junk_len, rng);

                if (opq_len + junk_len <= size - offset && offset + inst.len <= size) {
                    size_t move_len = size - offset - opq_len - junk_len;
                    if (offset + opq_len + junk_len <= size && move_len <= size) {
                        memmove(code + offset + opq_len + junk_len, code + offset, move_len);
                        memcpy(code + offset, opq_buf, opq_len);
                        memcpy(code + offset + opq_len, junk_buf, junk_len);
                    }
                    offset += opq_len + junk_len;
                    mutated = true;
                    continue;
                }
            }
        }

        if (!mutated && (chacha20_random(rng) % 10) < (mutation_intensity / 2)) {
            uint8_t junk_buf[32];
            size_t junk_len;
            spew_trash(junk_buf, &junk_len, rng);
            if (junk_len <= size - offset && offset + inst.len <= size) {
                size_t move_len = size - offset - junk_len;
                if (offset + junk_len <= size && move_len <= size) {
                    memmove(code + offset + junk_len, code + offset, move_len);
                    memcpy(code + offset, junk_buf, junk_len);
                }
                offset += junk_len;
                mutated = true;
                continue;
            }
        }

        /* Instruction splitting expand MOV reg,imm into equivalent sequences */
        if (!mutated && (inst.opcode[0] & 0xF8) == 0xB8 && inst.imm != 0 && inst.len >= 5) {
            uint8_t target_reg = inst.opcode[0] & 0x7;
            switch(chacha20_random(rng) % 30) { /*  Momma didn't raise no pussy */
                case 0: 
                    if (offset + 10 <= size) {
                        code[offset] = 0x48; 
                        code[offset+1] = 0x31;
                        code[offset+2] = 0xC0 | (target_reg << 3) | target_reg;
                        code[offset+3] = 0x48;
                        code[offset+4] = 0x81;
                        code[offset+5] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 6) = (uint32_t)inst.imm;
                    }
                    break;
                case 1: 
                    if (offset + 13 <= size) {
                        uint32_t half = (uint32_t)inst.imm / 2;
                        code[offset] = 0x48; code[offset+1] = 0xC7;
                        code[offset+2] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 3) = half;
                        code[offset+7] = 0x48; code[offset+8] = 0x81;
                        code[offset+9] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 10) = (uint32_t)inst.imm - half;
                    }
                    break;
                case 2: 
                    if (offset + 10 <= size) {
                        code[offset] = 0x48; code[offset+1] = 0x31;
                        code[offset+2] = 0xC0 | (target_reg << 3) | target_reg;
                        code[offset+3] = 0x48; code[offset+4] = 0x81;
                        code[offset+5] = 0xF0 | target_reg;
                        *(uint32_t*)(code + offset + 6) = ~(uint32_t)inst.imm;
                    }
                    break;
                case 3:
                    break;
                case 4:
                    if (offset + 10 <= size && inst.imm != 0x80000000 && inst.imm != 0) {
                        code[offset] = 0x48; code[offset+1] = 0xC7;
                        code[offset+2] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 3) = -(int32_t)inst.imm;
                        code[offset+7] = 0x48; code[offset+8] = 0xF7;
                        code[offset+9] = 0xD8 | target_reg;
                    }
                    break;
                case 5: 
                    if (offset + 10 <= size && inst.imm > 0) {
                        code[offset] = 0x48; code[offset+1] = 0xC7;
                        code[offset+2] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 3) = (uint32_t)inst.imm - 1;
                        code[offset+7] = 0x48; code[offset+8] = 0xFF;
                        code[offset+9] = 0xC0 | target_reg;  /*  INC */
                    }
                    break;
                case 6: /*  XOR reg,reg + XOR reg,imm (double XOR = value) */
                    if (offset + 14 <= size) {
                        code[offset] = 0x48; code[offset+1] = 0x31;
                        code[offset+2] = 0xC0 | (target_reg << 3) | target_reg;
                        code[offset+3] = 0x48; code[offset+4] = 0x81;
                        code[offset+5] = 0xF0 | target_reg;
                        *(uint32_t*)(code + offset + 6) = (uint32_t)inst.imm ^ 0xAAAAAAAA;
                        code[offset+10] = 0x48; code[offset+11] = 0x81;
                        code[offset+12] = 0xF0 | target_reg;
                        *(uint32_t*)(code + offset + 13) = 0xAAAAAAAA;
                    }
                    break;
                case 7: /*  MOV reg, imm*2 + SHR reg, 1 */
                    if (offset + 10 <= size && (inst.imm & 1) == 0) {  /*  Only if even */
                        code[offset] = 0x48; code[offset+1] = 0xC7;
                        code[offset+2] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 3) = (uint32_t)inst.imm * 2;
                        code[offset+7] = 0x48; code[offset+8] = 0xD1;
                        code[offset+9] = 0xE8 | target_reg; /*  SHR 1 */
                    }
                    break;
                case 8: /*  MOV reg, -imm + NEG reg (double NEG) */
                    if (offset + 10 <= size && inst.imm != 0x80000000) {
                        code[offset] = 0x48; code[offset+1] = 0xC7;
                        code[offset+2] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 3) = -(int32_t)inst.imm;
                        code[offset+7] = 0x48; code[offset+8] = 0xF7;
                        code[offset+9] = 0xD8 | target_reg; /*  NEG */
                    }
                    break;
                case 9: /*  MOV reg, part1 + ADD reg, part2 */
                    if (offset + 14 <= size) {
                        uint32_t part1 = (uint32_t)inst.imm / 3;
                        uint32_t part2 = (uint32_t)inst.imm - part1;
                        code[offset] = 0x48; code[offset+1] = 0xC7;
                        code[offset+2] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 3) = part1;
                        code[offset+7] = 0x48; code[offset+8] = 0x81;
                        code[offset+9] = 0xC0 | target_reg;
                        *(uint32_t*)(code + offset + 10) = part2;
                    }
                    break;
            }
        
            if (!is_op_ok(code + offset)) {
                if (offset + inst.len <= size && inst.len > 0) memcpy(code + offset, inst.raw, inst.len);
            } else {
                mutated = true;
            }
        }        

        if (!mutated && (chacha20_random(rng) % 10) < (mutation_intensity / 4)) {
            uint8_t orgi_op = inst.opcode[0];
            uint8_t new_opcode = orgi_op;
            switch(chacha20_random(rng) % 4) {
                case 0:
                    if (inst.has_modrm && modrm_reg(inst.modrm) == modrm_rm(inst.modrm)) new_opcode = (orgi_op == 0x89) ? 0x87 : 0x89;
                    break;
                case 1:
                    if (orgi_op == 0x01) new_opcode = 0x29;
                    else if (orgi_op == 0x29) new_opcode = 0x01;
                    break;
                case 2:
                    if (orgi_op == 0x21) new_opcode = 0x09;
                    else if (orgi_op == 0x09) new_opcode = 0x21;
                    break;
                case 3:
                    if (orgi_op == 0x31 && inst.has_modrm && modrm_reg(inst.modrm) == modrm_rm(inst.modrm)) new_opcode = 0x89;
                    break;
            }
            if (new_opcode != orgi_op) {
                code[offset] = new_opcode;
                if (is_op_ok(code + offset)) {
                    mutated = true;
                } else code[offset] = orgi_op;
            }
        }

        offset += inst.len;
    }

  
    if (gen > 5 && (chacha20_random(rng) % 10) < (gen > 15 ? 8 : 3)) {
        flowmap cfg;
        sketch_flow(code, size, &cfg);
        flatline_flow(code, size, &cfg, rng);
        free(cfg.blocks);
    }

    if (gen > 3 && (chacha20_random(rng) % 10) < (gen > 10 ? 5 : 2)) {
        shuffle_blocks(code, size, rng);
    }
}
#endif

__attribute__((always_inline)) inline __attribute__((always_inline)) inline void _mut8(uint8_t *code, size_t size, chacha_state_t *rng, unsigned gen) {
    if (!code || size == 0 || !rng) return;

    muttt_t mut_log;
    liveness_state_t liveness;
    init_mut(&mut_log);
    boot_live(&liveness);

    unsigned mutation_intensity = gen + 1;
    if (mutation_intensity > 20) mutation_intensity = 20;

#if defined(__x86_64__) || defined(_M_X64)
    size_t offset = 0;
    while (offset < size) {
        x86_inst_t inst;
        if (!decode_x86_withme(code + offset, size - offset, 0, &inst, NULL) || !inst.valid || inst.len == 0 || offset + inst.len > size) {
            offset++;
            continue;
        }
        scramble_x86(code + offset, inst.len, rng, gen, &mut_log, &liveness, mutation_intensity);
        offset += inst.len;
    }

    if ((chacha20_random(rng) % 10) < (mutation_intensity / 2)) {
        flowmap cfg;
        sketch_flow(code, size, &cfg);
        flatline_flow(code, size, &cfg, rng);
        drop_mut(&mut_log, 0, size, MUT_FLATTEN, gen, "CF BS");
        free(cfg.blocks);
    }

    if ((chacha20_random(rng) % 10) < (mutation_intensity / 3)) {
        shuffle_blocks(code, size, rng);
        drop_mut(&mut_log, 0, size, MUT_REORDER, gen, "Block reorder");
    }

#elif defined(__aarch64__) || defined(_M_ARM64)
    /*  Apply batch expansion first (gen 5+) */
    if (gen >= 5 && (chacha20_random(rng) % 10) < (gen > 10 ? 6 : 3)) {
        size_t new_size = expand_arm64_code_section(code, size, size * 2, &liveness, rng,
                                                     mutation_intensity * 2);
        if (new_size > size && new_size <= size * 2) {
            DBG("ARM64 batch expansion: %zu -> %zu bytes (+%zu)\n", 
                size, new_size, new_size - size);
            size = new_size;
            drop_mut(&mut_log, 0, new_size, MUT_EXPAND, gen, "arm64 batch expand");
        }
    }
    
    size_t offset = 0;
    while (offset + 4 <= size) {
        arm64_inst_t inst;
        if (!decode_arm64(code + offset, &inst) || !inst.valid) {
            offset += 4;
            continue;
        }
        
        if (liveness) pulse_live(&liveness, offset, &inst);
        
        /*  Apply ARM64 mutations */
        scramble_arm64(code + offset, 4, rng, gen, &mut_log, &liveness, mutation_intensity);
        
        offset += 4;
    }

    /*  Control flow mutations */
    if (gen > 5 && (chacha20_random(rng) % 10) < (gen > 15 ? 8 : 3)) {
        flowmap cfg;
        if (sketch_flow_arm64(code, size, &cfg)) {
            flatline_flow_arm64(code, size, &cfg, rng);
            drop_mut(&mut_log, 0, size, MUT_FLATTEN, gen, "arm64 control flow flattening");
            free(cfg.blocks);
        }
    }
    
    /*  Block reordering */
    if (gen > 3 && (chacha20_random(rng) % 10) < (gen > 10 ? 5 : 2)) {
        shuffle_blocks_arm64(code, size, rng);
        drop_mut(&mut_log, 0, size, MUT_REORDER, gen, "arm64 block reorder");
    }
#else
    /*  Do nothing */
    (void)code; (void)size; (void)rng; (void)gen;
#endif

    freeme(&mut_log);
}

/* Main entry point for code mutation */
void mutate(uint8_t *code, size_t size, chacha_state_t *rng, unsigned gen, engine_context_t *ctx) {
#if defined(__aarch64__) || defined(_M_ARM64)
    if (!code || size < 4 || !rng) return;
#else
    if (!code || size < 16 || !rng) return;
#endif

    if (ctx) {
        ctx->debug_code = code;
        ctx->debug_code_size = size;
    }

    _mut8(code, size, rng, gen);
}


/* Validation of mutated code */
static bool validate_mutated_code(const uint8_t *code, size_t size, size_t original_size) {
    if (!code || size == 0) return false;
    
    /*  Check size growth (max 3x original) */
    if (size > original_size * 3) {
        DBG("size %zu exceeds 3x original %zu\n", size, original_size);
        return false;
    }
    
#if defined(ARCH_ARM)
    /*  Must be 4-byte aligned */
    if ((size % 4) != 0) {
        DBG("ARM64 size %zu not 4-byte aligned\n", size);
        return false;
    }
    
    size_t valid_count = 0;
    size_t privileged_count = 0;
    
    for (size_t offset = 0; offset + 4 <= size; offset += 4) {
        arm64_inst_t inst;
        if (!decode_arm64(code + offset, &inst)) {
            DBG("decode error at offset %zu\n", offset);
            return false;
        }
        
        if (!inst.valid) {
            DBG("invalid instruction at offset %zu\n", offset);
            return false;
        }
        
        if (inst.ring0) {
            privileged_count++;
            DBG("Yo: privileged instruction at offset %zu\n", offset);
        }
        
        valid_count++;
    }
    
    if (privileged_count > 0) {
        DBG("Yo: %zu privileged instructions found\n", privileged_count);
    }
    
    DBG("%zu valid ARM64 instructions\n", valid_count);
    return true;
    
#else  /*  x86-64 */
    size_t valid_count = 0;
    size_t offset = 0;
    
    while (offset < size) {
        x86_inst_t inst;
        if (!decode_x86_withme(code + offset, size - offset, 0, &inst, NULL)) {
            offset++;
            continue;
        }
        
        if (!inst.valid) {
            offset++;
            continue;
        }
        
        if (inst.ring0) {
            DBG("Yo: privileged instruction at offset %zu\n", offset);
        }
        
        valid_count++;
        offset += inst.len;
    }
    
    DBG("%zu valid x86-64 instructions\n", valid_count);
    return valid_count > 0;
#endif
}

size_t decode_map(const uint8_t *code, size_t size, instr_info_t *out, size_t max) {
    size_t n = 0, off = 0;
    size_t cf_count = 0;
    size_t failed_decodes = 0;
    
#if defined(__x86_64__) || defined(_M_X64)
    while (off < size && n < max) {
        x86_inst_t inst;
        if (!decode_x86_withme(code + off, size - off, 0, &inst, NULL)) {
            failed_decodes++;
            off++;
            continue;
        }
        out[n].off = off;
        out[n].len = inst.len;
        out[n].type = inst.opcode[0];
        out[n].cf = inst.is_control_flow;
        out[n].valid = 1;
        memcpy(out[n].raw, code + off, inst.len > 16 ? 16 : inst.len);
        
        if (inst.is_control_flow) {
            cf_count++;
        }
        
        off += inst.len;
        n++;
    }
#elif defined(__aarch64__) || defined(_M_ARM64)
    while (off + 4 <= size && n < max) {
        arm64_inst_t inst;
        if (!decode_arm64(code + off, &inst) || !inst.valid) {
            failed_decodes++;
            off += 4;
            continue;
        }
        out[n].off = off;
        out[n].len = 4;
        out[n].type = inst.type;
        out[n].cf = inst.is_control_flow;
        out[n].valid = 1;
        memcpy(out[n].raw, code + off, 4);
        
        if (inst.is_control_flow) {
            cf_count++;
        }
        
        off += 4;
        n++;
    }
#endif
    
    if (failed_decodes > 0) {}
    if (cf_count > 0) {}    
    return n;
}
